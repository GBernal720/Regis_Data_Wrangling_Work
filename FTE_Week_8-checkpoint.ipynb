{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Week 8 - Web Scraping\n",
    "\n",
    "**Optional Reading:** <br>\n",
    "  Data Wrangling with Python, Chapter 11 and 12  (pages 279 - 359)\n",
    "\n",
    "**Highly Recommended Reading:** <br>\n",
    "   - https://www.dataquest.io/blog/web-scraping-tutorial-python/\n",
    "   - https://www.codingdojo.com/blog/html-vs-css-inforgraphic\n",
    "\n",
    "**Overview:**<br>\n",
    "\n",
    "* Web Scraping\n",
    "\n",
    "  * Online Tutorial\n",
    "\n",
    "    \n",
    "* Use Case: BeautifulSoup\n",
    "   - Web Page Inspection\n",
    "   - Web Scraping Example\n",
    "   \n",
    "\n",
    "* Use Case: gazpacho\n",
    "   - Tabular Data\n",
    "   - Multiple Tables on a Single Web Page "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Web Scraping\n",
    "\n",
    "In today's world, nearly everything can be found on the internet.  However, not everything is easily accessible. Web scarping is one way of mining data from the internet. Web scraping has two components: fetching the page and extracting data from the page. \n",
    "\n",
    "Fetching is the downloading of a page for use. If all you wanted to do was \"view\" a web page, the fetching is accomplished by your favorite broswer. Once fetched, then extraction can take place. The content of a page may be parsed, searched, reformatted, its data copied into a spreadsheet, and so on. Web scrapers typically take something out of a page, to make use of it for another purpose somewhere else. An example would be to find and copy names and phone numbers, or companies and their URLs, to a list (contact scraping).\n",
    "(https://en.wikipedia.org/wiki/Web_scraping)\n",
    "\n",
    "\n",
    "\n",
    "## Online Tutorial\n",
    "As mentioned above in the readings section of this FTE, please take the time to work through the online tutorial at https://www.dataquest.io/blog/web-scraping-tutorial-python/."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-warning\">\n",
    "<b>Note about Web Scraping:</b> Some websites frown upon their sites being scraped and they will block or blacklist your ip address with no warning. Proceed with caution!\n",
    "    \n",
    "Many websites publish a file for individuals to determine where or not scraping is allowed.  You can find this file by typing the domain name and the /robots.txt.  As an example, here is how you will find the robots.txt file for Regis's website. (https://www.regis.edu/robots.txt) \n",
    "```\n",
    "User-agent: *\n",
    "Disallow: /News-Events-Media/Event-Calendar/Event.aspx?*\n",
    "sitemap: /sitemap.xml\n",
    "```\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Use Case: BeautifulSoup \n",
    "The tutorial on dataquest uses the python library BeautifulSoup.  We will use BeautifulSoup to gather a couple of the text fields off of https://www.marketwatch.com/investing/index/djia"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Web Page Inspection\n",
    "Before we actually start scraping the information from thispage, let's inspect the page a little closer.\n",
    "\n",
    "<img align=\"center\" style=\"padding-right:10px;\" src=\"figures_8/DJIA_website.png\" width=600 >"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For this exercise, let's try to retrieve the information in the upper left corner directly under the title Dow Jones Industrial Average.\n",
    "\n",
    "<img align=\"center\" style=\"padding-right:10px;\" src=\"figures_8/DJIA_retrieve.png\" >"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As the tutorial pointed out, Chrome makes inspected the HTML tags on a web page very easy.  Upon, inspection, we can see the following:\n",
    "\n",
    "<img align=\"left\" style=\"padding-right:10px;\" src=\"figures_8/DJIA_inspection.png\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Web Scraping Example"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-success\">\n",
    "<b>Installation - requests and beautifulsoup4</b> <br>\n",
    "    pip install requests <br>\n",
    "    pip install beautifulsoup4\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: requests in c:\\users\\eltac\\anaconda3\\lib\\site-packages (2.22.0)\n",
      "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in c:\\users\\eltac\\anaconda3\\lib\\site-packages (from requests) (1.24.2)\n",
      "Requirement already satisfied: chardet<3.1.0,>=3.0.2 in c:\\users\\eltac\\anaconda3\\lib\\site-packages (from requests) (3.0.4)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\eltac\\anaconda3\\lib\\site-packages (from requests) (2019.9.11)\n",
      "Requirement already satisfied: idna<2.9,>=2.5 in c:\\users\\eltac\\anaconda3\\lib\\site-packages (from requests) (2.8)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install requests"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: beautifulsoup4 in c:\\users\\eltac\\anaconda3\\lib\\site-packages (4.8.0)\n",
      "Requirement already satisfied: soupsieve>=1.2 in c:\\users\\eltac\\anaconda3\\lib\\site-packages (from beautifulsoup4) (1.9.3)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install beautifulsoup4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Response [200]>"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "url = \"https://www.marketwatch.com/investing/index/djia\"\n",
    "page = requests.get(url)\n",
    "\n",
    "# verify the status_code is a 200\n",
    "page"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So far as good.  Time gather the data from the smaller section of the web page.\n",
    "\n",
    "From our inspection we can see that we need to retrieve the HTML tag `<div class=\"element element--intraday\">`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "soup = BeautifulSoup(page.content, 'html.parser')\n",
    "data = soup.find('div', class_='element element--intraday')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<div class=\"element element--intraday\">\n",
       "<small class=\"intraday__status status--closed\"><span class=\"company__ticker\">DJIA</span><span class=\"company__market\">US</span><i class=\"icon--lock\"></i><div class=\"status\">Closed</div><span class=\"scroll-top\">Back To Top</span></small>\n",
       "<div class=\"intraday__timestamp\">\n",
       "<span class=\"timestamp__time\">Last Updated: <bg-quote channel=\"/zigman2/quotes/210598065/realtime\" field=\"date\">Dec 13, 2019 5:14 p.m.</bg-quote> EST</span>\n",
       "</div>\n",
       "<div class=\"intraday__data\">\n",
       "<h3 class=\"intraday__price\">\n",
       "<sup class=\"character\"></sup>\n",
       "<span class=\"value\">28,135.38</span>\n",
       "</h3>\n",
       "<bg-quote channel=\"/zigman2/quotes/210598065/realtime\" class=\"intraday__change positive\">\n",
       "<i class=\"icon--caret\"></i>\n",
       "<span class=\"change--point--q\">3.33</span>\n",
       "<span class=\"change--percent--q\">0.01%</span>\n",
       "</bg-quote>\n",
       "</div>\n",
       "<div class=\"intraday__close\">\n",
       "<table class=\"table table--primary align--right\">\n",
       "<thead>\n",
       "<tr class=\"table__row\">\n",
       "<th class=\"table__heading\">Previous Close</th>\n",
       "</tr>\n",
       "</thead>\n",
       "<tbody class=\"remove-last-border\">\n",
       "<tr class=\"table__row\">\n",
       "<td class=\"table__cell u-semi\">28,132.05</td>\n",
       "</tr>\n",
       "</tbody>\n",
       "</table>\n",
       "</div>\n",
       "</div>"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# looking at all the HTML tags within this subsection of the web page\n",
    "data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "At this point we could use string manipulation to parse our data into the individual elements within this section of the web page. <br>\n",
    "<b> OR </b> <br> \n",
    "We could go after the individual elements by narrowing our search criteria within BeautifulSoup.\n",
    "\n",
    "Let's try to narrow our search and return the following specific elements:\n",
    "   * status of the market \n",
    "   * current price \n",
    "   * point amount of the change\n",
    "   * percentage of the change\n",
    "   * timestamp"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Might as well start working from the top of our list.\n",
    "\n",
    "HTML: status of the market<br>\n",
    "`<div class=\"status\">Closed</div>`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Closed'"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# status of the market\n",
    "status = soup.find('div', class_=\"status\").get_text()\n",
    "status"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Getting the price is going to be a little bit more interesting. The actual value is nested within a couple of HTML elements.\n",
    "\n",
    "Good news! We can chain our find() operations together.\n",
    "\n",
    "HTML: current price<br>\n",
    "`<h3 class=\"intraday__price\"> ` <br>\n",
    "`<sup class=\"character\"></sup>` <br>\n",
    "`<span class=\"value\">28,135.38</span>`<br>\n",
    "`</h3>`\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'28,239.28'"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# current price\n",
    "price = soup.find('h3', class_=\"intraday__price\").find('span', class_=\"value\").get_text()\n",
    "price"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "HTML: point amount of the change<br>\n",
    "`<span class=\"change--point--q\">3.33</span>`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'-27.88'"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# point amount of the change\n",
    "change_amount = soup.find('span', class_=\"change--point--q\").get_text()\n",
    "change_amount"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "HTML: percentage of the change <br>\n",
    "`<span class=\"change--percent--q\">0.01%</span>`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'-0.10%'"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# percentage of the change\n",
    "change_percentage = soup.find('span', class_=\"change--percent--q\").get_text()\n",
    "change_percentage"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "HTML: timestamp <br>\n",
    "`<span class=\"timestamp__time\">Last Updated: <bg-quote channel=\"/zigman2/quotes/210598065/realtime\" field=\"date\">`\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Dec 18, 2019 4:52 p.m.'"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# timestamp\n",
    "timestamp = soup.find('span', class_=\"timestamp__time\").find('bg-quote').get_text()\n",
    "timestamp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The current of the DJIA as of Dec 13, 2019 5:14 p.m. is 28,135.38. \n",
      "This is a change of 3.33 or 0.01% since the last report\n"
     ]
    }
   ],
   "source": [
    "# print all of our fields out\n",
    "print(f'The current of the DJIA as of {timestamp} is {price}. \\nThis is a change of {change_amount} or {change_percentage} since the last report')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Hooray! All of this matches the data found on the web page.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***\n",
    "# Use Case: Gazpacho\n",
    "gazpacho is a web scraping library. It replaces requests and BeautifulSoup for most projects. gazpacho is small, simple, fast, and consistent. (https://pypi.org/project/gazpacho/ and https://maxhumber.com/scraping_fantasy_hockey)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-success\">\n",
    "<b>Installation - gazpacho</b> <br>\n",
    "pip install -U gazpacho\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'https://www.marketwatch.com/investing/index/djia'"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# verify we still have the url of our web page\n",
    "url"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "#imports\n",
    "from gazpacho import get, Soup"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here's is where the power of gazpacho starts to come into play.  Notice that we don't need to use 2 python packages to fetch and extract our web page."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# fetch step\n",
    "html = get(url)\n",
    "\n",
    "# extract step\n",
    "soup = Soup(html)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<div class=\"element element--intraday\">\n",
       "                <small class=\"intraday__status status--closed\"><span class=\"company__ticker\">DJIA</span><span class=\"company__market\">US</span><i class=\"icon--lock\"></i><div class=\"status\">Closed</div><span class=\"scroll-top\">Back To Top</span></small>\n",
       "        \n",
       "            <div class=\"intraday__timestamp\">\n",
       "                <span class=\"timestamp__time\">Last Updated: <bg-quote field=\"date\" channel=\"/zigman2/quotes/210598065/realtime\">Dec 13, 2019 5:14 p.m.</bg-quote> EST</span>\n",
       "                \n",
       "            </div>\n",
       "            <div class=\"intraday__data\">\n",
       "                <h3 class=\"intraday__price \">\n",
       "                    <sup class=\"character\"></sup>\n",
       "                    <span class=\"value\">28,135.38</span>\n",
       "                </h3>\n",
       "                <bg-quote channel=\"/zigman2/quotes/210598065/realtime\" class=\"intraday__change positive\">\n",
       "                    <i class=\"icon--caret\"></i>\n",
       "                    <span class=\"change--point--q\">3.33</span>\n",
       "                    <span class=\"change--percent--q\">0.01%</span>\n",
       "                </bg-quote>\n",
       "            </div>\n",
       "\n",
       "\n",
       "\n",
       "            <div class=\"intraday__close\">\n",
       "                <table class=\"table table--primary align--right\">\n",
       "                    <thead>\n",
       "                        <tr class=\"table__row\">\n",
       "                                <th class=\"table__heading\">Previous Close</th>\n",
       "                        </tr>\n",
       "                    </thead>\n",
       "                    <tbody class=\"remove-last-border\">\n",
       "                        <tr class=\"table__row\">\n",
       "                            <td class=\"table__cell u-semi\">28,132.05</td>\n",
       "                        </tr>\n",
       "                    </tbody>\n",
       "                </table>\n",
       "            </div>\n",
       "        \n",
       "\n",
       "    </div>"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# use find() to parse a specific HTML\n",
    "gaz_data = soup.find('div', {'class':'element element--intraday'})\n",
    "gaz_data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Okay?!?!  So it's a little easier to scrap the web page with gazpacho, but it really doesn't seem to be a huge difference from BeautifulSoup at this point.\n",
    "\n",
    "***\n",
    "### Tabular Data\n",
    "One area that gazpacho makes really easy is in parsing a table within a webpage. The last section of our gaz_data has a web table within it.   Let's see how gazpacho handle the data in this table."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<div class=\"intraday__close\">\n",
       "                <table class=\"table table--primary align--right\">\n",
       "                    <thead>\n",
       "                        <tr class=\"table__row\">\n",
       "                                <th class=\"table__heading\">Previous Close</th>\n",
       "                        </tr>\n",
       "                    </thead>\n",
       "                    <tbody class=\"remove-last-border\">\n",
       "                        <tr class=\"table__row\">\n",
       "                            <td class=\"table__cell u-semi\">28,132.05</td>\n",
       "                        </tr>\n",
       "                    </tbody>\n",
       "                </table>\n",
       "            </div>"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# narrow things down to the table\n",
    "gaz_table = soup.find('div', {'class':'intraday__close'})\n",
    "gaz_table"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now if we could partner our extracted data with pandas dataframes to orgainize and store this information, that would be fabulous!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[   Previous Close\n",
       " 0        28132.05]"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "df = pd.read_html(str(gaz_table.html))\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Interesting!!  The data matches, but this does not look like a pandas df."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "list"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Oh! Since this is a list, we need to reference the index within the list."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Previous Close</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>28132.05</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Previous Close\n",
       "0        28132.05"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_html(str(gaz_table.html))[0]\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Awww.. Getting better...  But still not as impressive as it could have been.  That praticular table only has one row and column.  \n",
    "\n",
    "Let's try something a bit more impressive.   Let's try weather data for Denver, CO.\n",
    "(https://weather.com/weather/hourbyhour/l/40097af22d207c3c7e8e3bfa1102bc635296631a89ac0d4eb688f926f092f4fd)\n",
    "\n",
    "<img align=\"left\" style=\"padding-right:10px;\" src=\"figures_8/Weather_Den_CO.png\" width=600 >"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define our URL\n",
    "url_2 = \"https://weather.com/weather/hourbyhour/l/40097af22d207c3c7e8e3bfa1102bc635296631a89ac0d4eb688f926f092f4fd\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# fetch step\n",
    "html_2 = get(url_2)\n",
    "\n",
    "# extract step\n",
    "soup_2 = Soup(html_2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "One of the benefits of gazpacho in working with tabular data is that you really don't need to know the HTML tags to retrieve the information.  So, all we should need to do is pass our soup_2 variable to pandas."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Time</th>\n",
       "      <th>Description</th>\n",
       "      <th>Temp</th>\n",
       "      <th>Feels</th>\n",
       "      <th>Precip</th>\n",
       "      <th>Humidity</th>\n",
       "      <th>Wind</th>\n",
       "      <th>Unnamed: 7</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>7:15 pmSun</td>\n",
       "      <td>Cloudy</td>\n",
       "      <td>27°</td>\n",
       "      <td>27°</td>\n",
       "      <td>0%</td>\n",
       "      <td>63%</td>\n",
       "      <td>NNE 3 mph</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>8:00 pmSun</td>\n",
       "      <td>Cloudy</td>\n",
       "      <td>27°</td>\n",
       "      <td>27°</td>\n",
       "      <td>0%</td>\n",
       "      <td>68%</td>\n",
       "      <td>WSW 3 mph</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>NaN</td>\n",
       "      <td>9:00 pmSun</td>\n",
       "      <td>Cloudy</td>\n",
       "      <td>26°</td>\n",
       "      <td>22°</td>\n",
       "      <td>0%</td>\n",
       "      <td>74%</td>\n",
       "      <td>WSW 4 mph</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>NaN</td>\n",
       "      <td>10:00 pmSun</td>\n",
       "      <td>Cloudy</td>\n",
       "      <td>26°</td>\n",
       "      <td>22°</td>\n",
       "      <td>0%</td>\n",
       "      <td>78%</td>\n",
       "      <td>W 3 mph</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>NaN</td>\n",
       "      <td>11:00 pmSun</td>\n",
       "      <td>Cloudy</td>\n",
       "      <td>26°</td>\n",
       "      <td>22°</td>\n",
       "      <td>5%</td>\n",
       "      <td>73%</td>\n",
       "      <td>NW 4 mph</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>NaN</td>\n",
       "      <td>12:00 amMon</td>\n",
       "      <td>Cloudy</td>\n",
       "      <td>26°</td>\n",
       "      <td>26°</td>\n",
       "      <td>10%</td>\n",
       "      <td>74%</td>\n",
       "      <td>N 2 mph</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1:00 amMon</td>\n",
       "      <td>Cloudy</td>\n",
       "      <td>26°</td>\n",
       "      <td>22°</td>\n",
       "      <td>15%</td>\n",
       "      <td>72%</td>\n",
       "      <td>NE 4 mph</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2:00 amMon</td>\n",
       "      <td>Cloudy</td>\n",
       "      <td>25°</td>\n",
       "      <td>21°</td>\n",
       "      <td>20%</td>\n",
       "      <td>75%</td>\n",
       "      <td>NE 4 mph</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3:00 amMon</td>\n",
       "      <td>Cloudy</td>\n",
       "      <td>26°</td>\n",
       "      <td>21°</td>\n",
       "      <td>25%</td>\n",
       "      <td>75%</td>\n",
       "      <td>NNE 4 mph</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9</td>\n",
       "      <td>NaN</td>\n",
       "      <td>4:00 amMon</td>\n",
       "      <td>Cloudy</td>\n",
       "      <td>25°</td>\n",
       "      <td>20°</td>\n",
       "      <td>25%</td>\n",
       "      <td>77%</td>\n",
       "      <td>N 4 mph</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10</td>\n",
       "      <td>NaN</td>\n",
       "      <td>5:00 amMon</td>\n",
       "      <td>Cloudy</td>\n",
       "      <td>25°</td>\n",
       "      <td>20°</td>\n",
       "      <td>15%</td>\n",
       "      <td>77%</td>\n",
       "      <td>N 4 mph</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>11</td>\n",
       "      <td>NaN</td>\n",
       "      <td>6:00 amMon</td>\n",
       "      <td>Cloudy</td>\n",
       "      <td>24°</td>\n",
       "      <td>19°</td>\n",
       "      <td>15%</td>\n",
       "      <td>77%</td>\n",
       "      <td>NNW 4 mph</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>12</td>\n",
       "      <td>NaN</td>\n",
       "      <td>7:00 amMon</td>\n",
       "      <td>Cloudy</td>\n",
       "      <td>25°</td>\n",
       "      <td>18°</td>\n",
       "      <td>15%</td>\n",
       "      <td>75%</td>\n",
       "      <td>NNW 5 mph</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>13</td>\n",
       "      <td>NaN</td>\n",
       "      <td>8:00 amMon</td>\n",
       "      <td>Cloudy</td>\n",
       "      <td>25°</td>\n",
       "      <td>19°</td>\n",
       "      <td>15%</td>\n",
       "      <td>72%</td>\n",
       "      <td>NW 5 mph</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>14</td>\n",
       "      <td>NaN</td>\n",
       "      <td>9:00 amMon</td>\n",
       "      <td>Cloudy</td>\n",
       "      <td>26°</td>\n",
       "      <td>20°</td>\n",
       "      <td>10%</td>\n",
       "      <td>65%</td>\n",
       "      <td>NNW 5 mph</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>15</td>\n",
       "      <td>NaN</td>\n",
       "      <td>10:00 am Mon</td>\n",
       "      <td>Mostly Cloudy</td>\n",
       "      <td>27°</td>\n",
       "      <td>22°</td>\n",
       "      <td>5%</td>\n",
       "      <td>61%</td>\n",
       "      <td>N 5 mph</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    Time   Description           Temp Feels Precip Humidity Wind Unnamed: 7\n",
       "0    NaN    7:15 pmSun         Cloudy   27°    27°       0%  63%  NNE 3 mph\n",
       "1    NaN    8:00 pmSun         Cloudy   27°    27°       0%  68%  WSW 3 mph\n",
       "2    NaN    9:00 pmSun         Cloudy   26°    22°       0%  74%  WSW 4 mph\n",
       "3    NaN   10:00 pmSun         Cloudy   26°    22°       0%  78%    W 3 mph\n",
       "4    NaN   11:00 pmSun         Cloudy   26°    22°       5%  73%   NW 4 mph\n",
       "5    NaN   12:00 amMon         Cloudy   26°    26°      10%  74%    N 2 mph\n",
       "6    NaN    1:00 amMon         Cloudy   26°    22°      15%  72%   NE 4 mph\n",
       "7    NaN    2:00 amMon         Cloudy   25°    21°      20%  75%   NE 4 mph\n",
       "8    NaN    3:00 amMon         Cloudy   26°    21°      25%  75%  NNE 4 mph\n",
       "9    NaN    4:00 amMon         Cloudy   25°    20°      25%  77%    N 4 mph\n",
       "10   NaN    5:00 amMon         Cloudy   25°    20°      15%  77%    N 4 mph\n",
       "11   NaN    6:00 amMon         Cloudy   24°    19°      15%  77%  NNW 4 mph\n",
       "12   NaN    7:00 amMon         Cloudy   25°    18°      15%  75%  NNW 5 mph\n",
       "13   NaN    8:00 amMon         Cloudy   25°    19°      15%  72%   NW 5 mph\n",
       "14   NaN    9:00 amMon         Cloudy   26°    20°      10%  65%  NNW 5 mph\n",
       "15   NaN  10:00 am Mon  Mostly Cloudy   27°    22°       5%  61%    N 5 mph"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_html(str(soup_2.html))[0]\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "5 lines of code and we a dataframe witht he contents of the web page.  Not bad!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***\n",
    "\n",
    "### Multiple Tables on a Single Web Page\n",
    "What is we wanted to scrap a web page that contained multiple tables?\n",
    "\n",
    "Let's take a look at https://www.espn.com/college-football/stats <br>\n",
    "We can see that there are actually 6 smaller tables on this one page.\n",
    "\n",
    "<img align=\"left\" style=\"padding-right:10px;\" src=\"figures_8/College_stats.png\" width=600 >"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Hopefully gazpacho handles these as smoothly as the prior examples."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "college_stats = \"https://www.espn.com/college-football/stats\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Passing</th>\n",
       "      <th>YDS</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>1Anthony GordonWSU</td>\n",
       "      <td>5228</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>2Joe BurrowLSU</td>\n",
       "      <td>4715</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>3Josh LoveSJSU</td>\n",
       "      <td>3923</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>4Brock PurdyISU</td>\n",
       "      <td>3760</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>5Cole McDonaldHAW</td>\n",
       "      <td>3642</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>Complete Leaders</td>\n",
       "      <td>Complete Leaders</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              Passing               YDS\n",
       "0  1Anthony GordonWSU              5228\n",
       "1      2Joe BurrowLSU              4715\n",
       "2      3Josh LoveSJSU              3923\n",
       "3     4Brock PurdyISU              3760\n",
       "4   5Cole McDonaldHAW              3642\n",
       "5    Complete Leaders  Complete Leaders"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# fetch/extract\n",
    "html_stats = get(college_stats)\n",
    "soup_stats = Soup(html_stats)\n",
    "\n",
    "# store in df\n",
    "stats = pd.read_html(str(soup_stats.html))[0]\n",
    "stats"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Hmmm... we got one of the tables. In the prior examples, we had a list with a single element for one table.  Perhaps, each table is a separate list element."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "6"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(stats)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Looks like it.  So now we need to loop through `stats` and pull out each table into a separate dataframe.\n",
    "\n",
    "To do this we will create a dictionary were the key is a dataframe name and the value is the dataframe itself"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_dict={}\n",
    "for i in range(len(stats)):\n",
    "    stats = pd.read_html(str(soup_stats.html))[i]\n",
    "    name = 'stats_'+str(i)\n",
    "    df_dict[name]=stats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Tackles</th>\n",
       "      <th>TOT</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>1Evan WeaverCAL</td>\n",
       "      <td>172</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>2Dele HardingILL</td>\n",
       "      <td>148</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>3John LakoAKR</td>\n",
       "      <td>138</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>4Javahn FergursonNMSU</td>\n",
       "      <td>133</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>5Treshaun HaywardWMU</td>\n",
       "      <td>132</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>Complete Leaders</td>\n",
       "      <td>Complete Leaders</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                 Tackles               TOT\n",
       "0        1Evan WeaverCAL               172\n",
       "1       2Dele HardingILL               148\n",
       "2          3John LakoAKR               138\n",
       "3  4Javahn FergursonNMSU               133\n",
       "4   5Treshaun HaywardWMU               132\n",
       "5       Complete Leaders  Complete Leaders"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# verifying one of the dataframes for now\n",
    "df_dict['stats_3']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can loop through and printout each dataframe."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              Passing               YDS\n",
      "0  1Anthony GordonWSU              5228\n",
      "1      2Joe BurrowLSU              4715\n",
      "2      3Josh LoveSJSU              3923\n",
      "3     4Brock PurdyISU              3760\n",
      "4   5Cole McDonaldHAW              3642\n",
      "5    Complete Leaders  Complete Leaders\n",
      "               Rushing               YDS\n",
      "0   1Chuba HubbardOKST              1936\n",
      "1  2Jonathan TaylorWIS              1909\n",
      "2     3J.K. DobbinsOSU              1829\n",
      "3   4Malcolm PerryNAVY              1804\n",
      "4         5AJ DillonBC              1685\n",
      "5     Complete Leaders  Complete Leaders\n",
      "                  Receiving               YDS\n",
      "0         1Ja'Marr ChaseLSU              1498\n",
      "1         2Omar BaylessARST              1473\n",
      "2  3Antonio Gandy-GoldenLIB              1333\n",
      "3        4Devin DuvernayTEX              1294\n",
      "4         5Gabriel DavisUCF              1241\n",
      "5          Complete Leaders  Complete Leaders\n",
      "                 Tackles               TOT\n",
      "0        1Evan WeaverCAL               172\n",
      "1       2Dele HardingILL               148\n",
      "2          3John LakoAKR               138\n",
      "3  4Javahn FergursonNMSU               133\n",
      "4   5Treshaun HaywardWMU               132\n",
      "5       Complete Leaders  Complete Leaders\n",
      "                      Sacks              SACK\n",
      "0           1Chase YoungOSU              16.5\n",
      "1        2Alex HighsmithCLT              14.0\n",
      "2  2Hamilcar Rashed Jr.ORST              14.0\n",
      "3      2Gregory RousseauMIA              14.0\n",
      "4         5Curtis WeaverBSU              13.5\n",
      "5          Complete Leaders  Complete Leaders\n",
      "               Interceptions               INT\n",
      "0           1Meiko DotsonFAU                 9\n",
      "1    2Douglas Coleman IIITTU                 8\n",
      "2            2Luq BarcooSDSU                 8\n",
      "3  4Antoine Winfield Jr.MINN                 7\n",
      "4        5Grayland ArnoldBAY                 6\n",
      "5           Complete Leaders  Complete Leaders\n"
     ]
    }
   ],
   "source": [
    "# display each df - print will remove some of the pretty formatting\n",
    "for df in df_dict.values():\n",
    "    print(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Awesome!  We have all 6 tables and they compare with the information off the web page. \n",
    "\n",
    "Before we wrap things up, we should mention that you can use `find()` within a gazpacho extract. \n",
    "\n",
    "Let's go after the same 6 tables, but narrow the extract search first.\n",
    "<img align=\"left\" style=\"padding-right:10px;\" src=\"figures_8/College_stats_inspect.png\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "HTML: \n",
    "`<div class=\"layout__column layout__column--1\">`<br>\n",
    "`<section class=\"Card statistics__main\">`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "stats_narrowed_search = soup_stats.find('div', {'class':'layout__column layout__column--1'}) \\\n",
    "                                  .find('section', {'class':\"Card statistics__main\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Tackles</th>\n",
       "      <th>TOT</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>1Evan WeaverCAL</td>\n",
       "      <td>172</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>2Dele HardingILL</td>\n",
       "      <td>148</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>3John LakoAKR</td>\n",
       "      <td>138</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>4Javahn FergursonNMSU</td>\n",
       "      <td>133</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>5Treshaun HaywardWMU</td>\n",
       "      <td>132</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>Complete Leaders</td>\n",
       "      <td>Complete Leaders</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                 Tackles               TOT\n",
       "0        1Evan WeaverCAL               172\n",
       "1       2Dele HardingILL               148\n",
       "2          3John LakoAKR               138\n",
       "3  4Javahn FergursonNMSU               133\n",
       "4   5Treshaun HaywardWMU               132\n",
       "5       Complete Leaders  Complete Leaders"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# let's go after just one of the tables\n",
    "stats_narrowed = pd.read_html(str(stats_narrowed_search.html))[3]\n",
    "stats_narrowed"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Recap\n",
    "\n",
    "<div class=\"alert alert-block alert-info\">\n",
    "<b>Helpful Hint::</b> Use the tool that matches the activity\n",
    "</div>\n",
    "\n",
    "As we have seen multiple times throughout this course, the selection of your toolset an important consideration in any data engineering effort. Almost always, there are multiple ways to complete any data engineering task. Depending on the libraries and data structures you elect to use, the difficulty of your task will vary."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
