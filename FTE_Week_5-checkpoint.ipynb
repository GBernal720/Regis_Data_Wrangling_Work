{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "inputHidden": false,
    "outputHidden": false
   },
   "source": [
    "# Week 5 - Data cleaning, formatting, standardizing, and investigation \n",
    "\n",
    "**Outline:**\n",
    "\n",
    "* First look at the data\n",
    "    * Investigate data in text editor\n",
    "    * Read the files in to a list variable\n",
    "* Devising a strategy\n",
    "* Kung-fu Pandas\n",
    "* Feature Engineering\n",
    "* Normalizing and choosing columns\n",
    "\n",
    "Heart disease data set: https://archive.ics.uci.edu/ml/datasets/Heart+Disease \n",
    "\n",
    "\n",
    "\n",
    "**NOTE: The Cleveland data file in the original data set is corrupt. Even though I included it, I'm going to ignore it.** "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "inputHidden": false,
    "outputHidden": false
   },
   "source": [
    "## First look at the data\n",
    "\n",
    "The original dataset has a really funky format. It is space separated and each record is several rows. Not a comma in sight, and what's with all the -9s?\n",
    "\n",
    "```\n",
    "1254 0 40 1 1 0 0\n",
    "-9 2 140 0 289 -9 -9 -9\n",
    "0 -9 -9 0 12 16 84 0\n",
    "0 0 0 0 150 18 -9 7\n",
    "172 86 200 110 140 86 0 0\n",
    "0 -9 26 20 -9 -9 -9 -9\n",
    "-9 -9 -9 -9 -9 -9 -9 12\n",
    "20 84 0 -9 -9 -9 -9 -9\n",
    "-9 -9 -9 -9 -9 1 1 1\n",
    "1 1 -9. -9. name\n",
    "1255 0 49 0 1 0 0\n",
    "-9 3 160 1 180 -9 -9 -9\n",
    "0 -9 -9 0 11 16 84 0\n",
    "0 0 0 0 -9 10 9 7\n",
    "156 100 220 106 160 90 0 0\n",
    "1 2 14 13 -9 -9 -9 -9\n",
    "-9 -9 -9 -9 -9 -9 -9 11\n",
    "20 84 1 -9 -9 2 -9 -9\n",
    "-9 -9 -9 -9 -9 1 1 1\n",
    "1 1 -9. -9. name\n",
    "```\n",
    "\n",
    "Hmmmm... it already seems like I can see some patterns. For example, I see what looks like two consecutive numbers (1254 & 1255), and just before the second number I see \"name\". Maybe the number is a record number? and \"name\" is the last field in the record?\n",
    "\n",
    "Let's read the good files in to a list and check it out."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "lines_list = []\n",
    "files = ['C:/Users/eltac/Downloads/data_5/data_5/hungarian.data',\n",
    "        'C:/Users/eltac/Downloads/data_5/data_5/long-beach-va.data',\n",
    "        'C:/Users/eltac/Downloads/data_5/data_5/switzerland.data']\n",
    "for file in files:\n",
    "    with open(file) as infile:\n",
    "        for line in infile:\n",
    "            if len(line) > 1:    # Blank lines at the end of files.\n",
    "                lines_list.append(line.strip()) # strip() leaves empty blank lines -- skip these\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's look at some of the lines:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['1254 0 40 1 1 0 0',\n",
       " '-9 2 140 0 289 -9 -9 -9',\n",
       " '0 -9 -9 0 12 16 84 0',\n",
       " '0 0 0 0 150 18 -9 7',\n",
       " '172 86 200 110 140 86 0 0',\n",
       " '0 -9 26 20 -9 -9 -9 -9',\n",
       " '-9 -9 -9 -9 -9 -9 -9 12',\n",
       " '20 84 0 -9 -9 -9 -9 -9',\n",
       " '-9 -9 -9 -9 -9 1 1 1',\n",
       " '1 1 -9. -9. name',\n",
       " '1255 0 49 0 1 0 0',\n",
       " '-9 3 160 1 180 -9 -9 -9',\n",
       " '0 -9 -9 0 11 16 84 0',\n",
       " '0 0 0 0 -9 10 9 7',\n",
       " '156 100 220 106 160 90 0 0',\n",
       " '1 2 14 13 -9 -9 -9 -9',\n",
       " '-9 -9 -9 -9 -9 -9 -9 11',\n",
       " '20 84 1 -9 -9 2 -9 -9',\n",
       " '-9 -9 -9 -9 -9 1 1 1',\n",
       " '1 1 -9. -9. name']"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lines_list[:20]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Hmmm... we listed 20 lines and got what looks like 2 full records. How many records did we get in total?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "6170"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(lines_list)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "inputHidden": false,
    "outputHidden": false
   },
   "source": [
    "So, 6,170 lines in 3 data files means about 2,000 lines per file, and 6170 is an even multiple of 10 so that adds evidence to the \"10 lines per record\" theory. If we can count on that it will make restructuring easy.\n",
    "\n",
    "***\n",
    "\n",
    "## Devising a strategy\n",
    "\n",
    "More experienced programmers probably already have an idea how they would approach this file. Beginners might be hiding under their desk. Either way, we should probably have a strategy.\n",
    "\n",
    "As Yogi Berra once said, **\"If you don't know where you are going, you might wind up someplace else.\"** I'll let you meditate on the wisdom of that statement on your own.\n",
    "\n",
    "Maybe a more useful way to think of it is in the words of Steve Mariboli, \"If you don’t know exactly where you’re going, how will you know when you get there?”\n",
    "\n",
    "\n",
    "So, where are you going with this data wrangling? Personally, I'd like to get it into a form that Pandas can easily ingest. This means lines joined together, comma separated values, string-numbers translated to int or float, and -- Oh, yeah, column names might be nice!\n",
    "\n",
    "Here are the general steps I'll follow:\n",
    "\n",
    "1. Replace spaces with commas -- this should get us most of the way to the CSV.\n",
    "2. Concatenate the 10-field record into one string. \n",
    "    * An alternative here might be to bring in the column names and make a list of dictionaries so we can use `json.dump()`.\n",
    "    * This might be a good place to deal with `int` conversions.\n",
    "    * May also want to deal with NaNs here too (the -9s).\n",
    "\n",
    "\n",
    "Let's replace spaces with commas."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "cleaned_lines = []\n",
    "for line in lines_list:\n",
    "    cleaned_lines.append(line.replace(' ', ','))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "inputHidden": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "outputHidden": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['4073,0,54,1,1,1,1',\n",
       " '-9,4,130,0,0,-9,-9,-9',\n",
       " '-9,-9,-9,0,7,3,85,0',\n",
       " '0,0,0,0,12,9.5,-9,150',\n",
       " '110,58,160,85,130,80,1,0',\n",
       " '3,2,-9,-9,-9,-9,-9,-9',\n",
       " '-9,-9,-9,7,2,0,-9,7',\n",
       " '4,85,3,1,2,1,1,2',\n",
       " '1,1,1,2,1,1,1,1',\n",
       " '1,1,-9.,-9.,name',\n",
       " '4074,0,66,0,1,1,1',\n",
       " '-9,4,155,0,0,-9,-9,-9',\n",
       " '-9,-9,-9,0,7,3,85,0',\n",
       " '0,0,0,0,12,6.5,-9,75',\n",
       " '90,66,190,90,155,90,0,0',\n",
       " '0,-9,-9,-9,-9,-9,-9,-9',\n",
       " '-9,-9,-9,7,1,0,-9,7',\n",
       " '4,85,1,1,1,1,1,1',\n",
       " '1,1,1,2,1,1,1,1',\n",
       " '1,1,70,-9.,name']"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cleaned_lines[-20:]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we need to concatenate the lines. Let's experiment on a small subset first."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_subset = cleaned_lines[:30]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1254,0,40,1,1,0,0-9,2,140,0,289,-9,-9,-90,-9,-9,0,12,16,84,00,0,0,0,150,18,-9,7172,86,200,110,140,86,0,00,-9,26,20,-9,-9,-9,-9-9,-9,-9,-9,-9,-9,-9,1220,84,0,-9,-9,-9,-9,-9-9,-9,-9,-9,-9,1,1,11,1,-9.,-9.,name\n",
      "1255,0,49,0,1,0,0-9,3,160,1,180,-9,-9,-90,-9,-9,0,11,16,84,00,0,0,0,-9,10,9,7156,100,220,106,160,90,0,01,2,14,13,-9,-9,-9,-9-9,-9,-9,-9,-9,-9,-9,1120,84,1,-9,-9,2,-9,-9-9,-9,-9,-9,-9,1,1,11,1,-9.,-9.,name\n",
      "1256,0,37,1,1,0,0-9,2,130,0,283,-9,-9,-90,-9,-9,1,11,21,84,00,0,0,0,100,10,-9,598,58,180,100,130,80,0,00,-9,17,14,-9,-9,-9,-9-9,-9,-9,-9,-9,-9,-9,1126,84,0,-9,-9,-9,-9,-9-9,-9,-9,-9,-9,1,1,11,1,-9.,-9.,name\n"
     ]
    }
   ],
   "source": [
    "row = '' # Just creates the variable\n",
    "\n",
    "for line in (data_subset):\n",
    "    row += line\n",
    "    if 'name' in line:\n",
    "        print(row)\n",
    "        row = ''\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Based on seeing a couple of '00' and '1220' or '1120', I think we need to add a comma after concatenating each line. Of course, that will put an extra comma at the end of the line... \\<sigh>, it's always something..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1254,0,40,1,1,0,0,-9,2,140,0,289,-9,-9,-9,0,-9,-9,0,12,16,84,0,0,0,0,0,150,18,-9,7,172,86,200,110,140,86,0,0,0,-9,26,20,-9,-9,-9,-9,-9,-9,-9,-9,-9,-9,-9,12,20,84,0,-9,-9,-9,-9,-9,-9,-9,-9,-9,-9,1,1,1,1,1,-9.,-9.,name\n",
      "1255,0,49,0,1,0,0,-9,3,160,1,180,-9,-9,-9,0,-9,-9,0,11,16,84,0,0,0,0,0,-9,10,9,7,156,100,220,106,160,90,0,0,1,2,14,13,-9,-9,-9,-9,-9,-9,-9,-9,-9,-9,-9,11,20,84,1,-9,-9,2,-9,-9,-9,-9,-9,-9,-9,1,1,1,1,1,-9.,-9.,name\n",
      "1256,0,37,1,1,0,0,-9,2,130,0,283,-9,-9,-9,0,-9,-9,1,11,21,84,0,0,0,0,0,100,10,-9,5,98,58,180,100,130,80,0,0,0,-9,17,14,-9,-9,-9,-9,-9,-9,-9,-9,-9,-9,-9,11,26,84,0,-9,-9,-9,-9,-9,-9,-9,-9,-9,-9,1,1,1,1,1,-9.,-9.,name\n"
     ]
    }
   ],
   "source": [
    "row = '' # Just creates the variable\n",
    "\n",
    "for line in (data_subset):\n",
    "    row += line + ','\n",
    "    if 'name' in line:\n",
    "        print(row[:-1]) # for ending comma\n",
    "        row = ''\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "That looks pretty good. Let's do it for real, but store the row in a list rather than print it out. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "joined_rows = []\n",
    "row = '' # Just creates the variable\n",
    "\n",
    "for line in (cleaned_lines):\n",
    "    row += line + ','\n",
    "    if 'name' in line:\n",
    "        joined_rows.append(row[:-1])\n",
    "        row = ''\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "617"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(joined_rows)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "617 is 6170 / 10, so, that checks out. \n",
    "\n",
    "<hr>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Adding header data\n",
    "\n",
    "The headers (as well as other info, like, about NULLs) is contained in a text file, \"heart-disease.names.' Here, I'll just copy the data out of the text file and use it as a block quote.\n",
    "\n",
    "These names are annoyingly non-uniform. Some end with ':', the categories don't have numbers but do have minus signs. As a matter of fact, I think I won't even bother with the categories -- they don't add anything to the column names."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "block_text='''1 id: patient identification number\n",
    "2 ccf: social security number (I replaced this with a dummy value of 0)\n",
    "3 age: age in years\n",
    "4 sex: sex (1 = male; 0 = female)\n",
    "5 painloc: chest pain location (1 = substernal; 0 = otherwise)\n",
    "6 painexer (1 = provoked by exertion; 0 = otherwise)\n",
    "7 relrest (1 = relieved after rest; 0 = otherwise)\n",
    "8 pncaden (sum of 5, 6, and 7)\n",
    "9 cp: chest pain type\n",
    "10 trestbps: resting blood pressure (in mm Hg on admission to the hospital)\n",
    "11 htn\n",
    "12 chol: serum cholestoral in mg/dl\n",
    "13 smoke: I believe this is 1 = yes; 0 = no (is or is not a smoker)\n",
    "14 cigs (cigarettes per day)\n",
    "15 years (number of years as a smoker)\n",
    "16 fbs: (fasting blood sugar > 120 mg/dl)  (1 = true; 0 = false)\n",
    "17 dm (1 = history of diabetes; 0 = no such history)\n",
    "18 famhist: family history of coronary artery disease (1 = yes; 0 = no)\n",
    "19 restecg: resting electrocardiographic results\n",
    "20 ekgmo (month of exercise ECG reading)\n",
    "21 ekgday (day of exercise ECG reading)\n",
    "22 ekgyr (year of exercise ECG reading)\n",
    "23 dig (digitalis used furing exercise ECG: 1 = yes; 0 = no)\n",
    "24 prop (Beta blocker used during exercise ECG: 1 = yes; 0 = no)\n",
    "25 nitr (nitrates used during exercise ECG: 1 = yes; 0 = no)\n",
    "26 pro (calcium channel blocker used during exercise ECG: 1 = yes; 0 = no)\n",
    "27 diuretic (diuretic used used during exercise ECG: 1 = yes; 0 = no)\n",
    "28 proto: exercise protocol\n",
    "29 thaldur: duration of exercise test in minutes\n",
    "30 thaltime: time when ST measure depression was noted\n",
    "31 met: mets achieved\n",
    "32 thalach: maximum heart rate achieved\n",
    "33 thalrest: resting heart rate\n",
    "34 tpeakbps: peak exercise blood pressure (first of 2 parts)\n",
    "35 tpeakbpd: peak exercise blood pressure (second of 2 parts)\n",
    "36 dummy\n",
    "37 trestbpd: resting blood pressure\n",
    "38 exang: exercise induced angina (1 = yes; 0 = no)\n",
    "39 xhypo: (1 = yes; 0 = no)\n",
    "40 oldpeak = ST depression induced by exercise relative to rest\n",
    "41 slope: the slope of the peak exercise ST segment\n",
    "42 rldv5: height at rest\n",
    "43 rldv5e: height at peak exercise\n",
    "44 ca: number of major vessels (0-3) colored by flourosopy\n",
    "45 restckm: irrelevant\n",
    "46 exerckm: irrelevant\n",
    "47 restef: rest raidonuclid (sp?) ejection fraction\n",
    "48 restwm: rest wall (sp?) motion abnormality\n",
    "49 exeref: exercise radinalid (sp?) ejection fraction\n",
    "50 exerwm: exercise wall (sp?) motion \n",
    "51 thal: 3 = normal; 6 = fixed defect; 7 = reversable defect\n",
    "52 thalsev: not used\n",
    "53 thalpul: not used\n",
    "54 earlobe: not used\n",
    "55 cmo: month of cardiac cath (sp?)  (perhaps \"call\")\n",
    "56 cday: day of cardiac cath (sp?)\n",
    "57 cyr: year of cardiac cath (sp?)\n",
    "58 num: diagnosis of heart disease (angiographic disease status)\n",
    "59 lmt\n",
    "60 ladprox\n",
    "61 laddist\n",
    "62 diag\n",
    "63 cxmain\n",
    "64 ramus\n",
    "65 om1\n",
    "66 om2\n",
    "67 rcaprox\n",
    "68 rcadist\n",
    "69 lvx1: not used\n",
    "70 lvx2: not used\n",
    "71 lvx3: not used\n",
    "72 lvx4: not used\n",
    "73 lvf: not used\n",
    "74 cathef: not used\n",
    "75 junk: not used\n",
    "76 name: last name of patient'''"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, this should look like lines of text with `\\n` at the end. We can split on the end of line."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "column_text = block_text.split('\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['1 id: patient identification number',\n",
       " '2 ccf: social security number (I replaced this with a dummy value of 0)',\n",
       " '3 age: age in years',\n",
       " '4 sex: sex (1 = male; 0 = female)',\n",
       " '5 painloc: chest pain location (1 = substernal; 0 = otherwise)']"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "column_text[:5]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "With a little bit of editor magic earlier **(remind me to show you how to do BLOCK SELECT)**, every element in our list has the format:\n",
    "\n",
    "`##<space>column_name`\n",
    "So, if we split on the space, element \\#1 holds the column name. We'll deal with colons later."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['66', 'om2']"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# First, a test of the split on an element that doesn't have text after the column name\n",
    "# Space is split's default but I'll specify it anyway for clarity.\n",
    "column_text[65].split(' ')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'om2'"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "column_text[65].split(' ')[1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I think tnat gives us enough to get the column headers. A list comprehension should do it. Maybe can get tricky and get rid of the colon, too.\n",
    "\n",
    "### <center>WARNING: Computer Science nerdistry ahead <br>https://www.urbandictionary.com/define.php?term=Nerdistry</center>\n",
    "\n",
    "Remmber: \n",
    "\n",
    "* Each element in the column_text list is a string, and when we use an index to reference an individual element, we are operating on the actual element.\n",
    "* `split()` returns a list, so you can put `[]` on the end to reference one particular element from the split.\n",
    "* Finally, a \"string\" is just a container for characters, and is iterable and indexable.\n",
    "\n",
    "At first, it may seem odd to see the `[]` on the end of a function call like `split()` or a second pair of `[]` to reference a character in a string after a split but it is actually just a application of *method chaining* -- using the output of one function as the input of the next function. \n",
    "\n",
    "This is all accomplished through the miracle of function associativity. Functions with the same precedence associate left to right, meaning that when an answer from a function `return`s, it is used as input to the next function to the right. A simple example would be:\n",
    "\n",
    "`x = 3 + 4 - 1`\n",
    "\n",
    "Last week, I mentioned **dunder methods**, or functions that are internal to classes / objects that affect aspects of how the object behaves. The example given was overriding the `__str__` function to nicely format our MailMessages when we printed them. In our addition example above, we took advantage of the `__add__` function behavior of integer objects (yes, **integer addition is a function and it can be overriden to do change the behavior of addition** ). Similarly, the `[]` is actually an operator, just like `+` and it has a dunder method called `__getitem__`.\n",
    "\n",
    "***\n",
    "\n",
    "The previous explanation was provided in hopes that you will learn the **_reason_** why chaining functions and indexes works rather than trying to rote-memorize the pattern. When you understand the actual mechanism at work, you can easily figure out how to reference any element buried in any data structure, regardless how deep or what kind of container."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "painloc:\n",
      "painloc\n"
     ]
    }
   ],
   "source": [
    "print(column_text[4].split(' ')[1])\n",
    "print(column_text[4].split(' ')[1][:-1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "headers = [column.split(' ')[1][:-1] if ':' in column else column.split(' ')[1] for column in column_text ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['id',\n",
       " 'ccf',\n",
       " 'age',\n",
       " 'sex',\n",
       " 'painloc',\n",
       " 'painexer',\n",
       " 'relrest',\n",
       " 'pncaden',\n",
       " 'cp',\n",
       " 'trestbps',\n",
       " 'htn',\n",
       " 'chol',\n",
       " 'smoke',\n",
       " 'cigs',\n",
       " 'years',\n",
       " 'fbs',\n",
       " 'dm',\n",
       " 'famhist',\n",
       " 'restecg',\n",
       " 'ekgmo',\n",
       " 'ekgday',\n",
       " 'ekgyr',\n",
       " 'di',\n",
       " 'pro',\n",
       " 'nit',\n",
       " 'pr',\n",
       " 'diureti',\n",
       " 'proto',\n",
       " 'thaldur',\n",
       " 'thaltime',\n",
       " 'met',\n",
       " 'thalach',\n",
       " 'thalrest',\n",
       " 'tpeakbps',\n",
       " 'tpeakbpd',\n",
       " 'dummy',\n",
       " 'trestbpd',\n",
       " 'exang',\n",
       " 'xhypo',\n",
       " 'oldpeak',\n",
       " 'slope',\n",
       " 'rldv5',\n",
       " 'rldv5e',\n",
       " 'ca',\n",
       " 'restckm',\n",
       " 'exerckm',\n",
       " 'restef',\n",
       " 'restwm',\n",
       " 'exeref',\n",
       " 'exerwm',\n",
       " 'thal',\n",
       " 'thalsev',\n",
       " 'thalpul',\n",
       " 'earlobe',\n",
       " 'cmo',\n",
       " 'cday',\n",
       " 'cyr',\n",
       " 'num',\n",
       " 'lmt',\n",
       " 'ladprox',\n",
       " 'laddist',\n",
       " 'diag',\n",
       " 'cxmain',\n",
       " 'ramus',\n",
       " 'om1',\n",
       " 'om2',\n",
       " 'rcaprox',\n",
       " 'rcadist',\n",
       " 'lvx1',\n",
       " 'lvx2',\n",
       " 'lvx3',\n",
       " 'lvx4',\n",
       " 'lvf',\n",
       " 'cathef',\n",
       " 'junk',\n",
       " 'name']"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "headers"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Seems to have worked! We'll use the zip-dict-list trick from week 2 and just dump it to file as JSON."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "rows = [row.split(',') for row in joined_rows]\n",
    "heart_disease_json = [dict(zip(headers,row)) for row in rows]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'id': '1255',\n",
       " 'ccf': '0',\n",
       " 'age': '49',\n",
       " 'sex': '0',\n",
       " 'painloc': '1',\n",
       " 'painexer': '0',\n",
       " 'relrest': '0',\n",
       " 'pncaden': '-9',\n",
       " 'cp': '3',\n",
       " 'trestbps': '160',\n",
       " 'htn': '1',\n",
       " 'chol': '180',\n",
       " 'smoke': '-9',\n",
       " 'cigs': '-9',\n",
       " 'years': '-9',\n",
       " 'fbs': '0',\n",
       " 'dm': '-9',\n",
       " 'famhist': '-9',\n",
       " 'restecg': '0',\n",
       " 'ekgmo': '11',\n",
       " 'ekgday': '16',\n",
       " 'ekgyr': '84',\n",
       " 'di': '0',\n",
       " 'pro': '0',\n",
       " 'nit': '0',\n",
       " 'pr': '0',\n",
       " 'diureti': '0',\n",
       " 'proto': '-9',\n",
       " 'thaldur': '10',\n",
       " 'thaltime': '9',\n",
       " 'met': '7',\n",
       " 'thalach': '156',\n",
       " 'thalrest': '100',\n",
       " 'tpeakbps': '220',\n",
       " 'tpeakbpd': '106',\n",
       " 'dummy': '160',\n",
       " 'trestbpd': '90',\n",
       " 'exang': '0',\n",
       " 'xhypo': '0',\n",
       " 'oldpeak': '1',\n",
       " 'slope': '2',\n",
       " 'rldv5': '14',\n",
       " 'rldv5e': '13',\n",
       " 'ca': '-9',\n",
       " 'restckm': '-9',\n",
       " 'exerckm': '-9',\n",
       " 'restef': '-9',\n",
       " 'restwm': '-9',\n",
       " 'exeref': '-9',\n",
       " 'exerwm': '-9',\n",
       " 'thal': '-9',\n",
       " 'thalsev': '-9',\n",
       " 'thalpul': '-9',\n",
       " 'earlobe': '-9',\n",
       " 'cmo': '11',\n",
       " 'cday': '20',\n",
       " 'cyr': '84',\n",
       " 'num': '1',\n",
       " 'lmt': '-9',\n",
       " 'ladprox': '-9',\n",
       " 'laddist': '2',\n",
       " 'diag': '-9',\n",
       " 'cxmain': '-9',\n",
       " 'ramus': '-9',\n",
       " 'om1': '-9',\n",
       " 'om2': '-9',\n",
       " 'rcaprox': '-9',\n",
       " 'rcadist': '-9',\n",
       " 'lvx1': '1',\n",
       " 'lvx2': '1',\n",
       " 'lvx3': '1',\n",
       " 'lvx4': '1',\n",
       " 'lvf': '1',\n",
       " 'cathef': '-9.',\n",
       " 'junk': '-9.',\n",
       " 'name': 'name'}"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "heart_disease_json[1] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"data_5/heart_disease.json\",'w') as outfile:\n",
    "    json.dump(heart_disease_json, outfile)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<hr>\n",
    "\n",
    "## Kung-fu Pandas\n",
    "\n",
    "All of that work just to get it in a form that Pandas can read!\n",
    "\n",
    "Now the **REAL** fun can begin!\n",
    "\n",
    "Careful examination of the `heart-disease.names` file (**you _did_ read that file, right?**) tells us that the -9s are NaN values. Pandas can do the conversion as it reads a CSV file with `na_values = '-9'`. Unfortunately, we are out of luck with json files. \n",
    "\n",
    "Pandas can also make a best-guess as to the column types using a variety of methods."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_json('data_5/heart_disease.json', orient = 'records')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "inputHidden": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "outputHidden": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>ccf</th>\n",
       "      <th>age</th>\n",
       "      <th>sex</th>\n",
       "      <th>painloc</th>\n",
       "      <th>painexer</th>\n",
       "      <th>relrest</th>\n",
       "      <th>pncaden</th>\n",
       "      <th>cp</th>\n",
       "      <th>trestbps</th>\n",
       "      <th>...</th>\n",
       "      <th>rcaprox</th>\n",
       "      <th>rcadist</th>\n",
       "      <th>lvx1</th>\n",
       "      <th>lvx2</th>\n",
       "      <th>lvx3</th>\n",
       "      <th>lvx4</th>\n",
       "      <th>lvf</th>\n",
       "      <th>cathef</th>\n",
       "      <th>junk</th>\n",
       "      <th>name</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>1254</td>\n",
       "      <td>0</td>\n",
       "      <td>40</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>-9</td>\n",
       "      <td>2</td>\n",
       "      <td>140</td>\n",
       "      <td>...</td>\n",
       "      <td>-9</td>\n",
       "      <td>-9</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>-9.0</td>\n",
       "      <td>-9.0</td>\n",
       "      <td>name</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>1255</td>\n",
       "      <td>0</td>\n",
       "      <td>49</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>-9</td>\n",
       "      <td>3</td>\n",
       "      <td>160</td>\n",
       "      <td>...</td>\n",
       "      <td>-9</td>\n",
       "      <td>-9</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>-9.0</td>\n",
       "      <td>-9.0</td>\n",
       "      <td>name</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>1256</td>\n",
       "      <td>0</td>\n",
       "      <td>37</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>-9</td>\n",
       "      <td>2</td>\n",
       "      <td>130</td>\n",
       "      <td>...</td>\n",
       "      <td>-9</td>\n",
       "      <td>-9</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>-9.0</td>\n",
       "      <td>-9.0</td>\n",
       "      <td>name</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>1257</td>\n",
       "      <td>0</td>\n",
       "      <td>48</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>-9</td>\n",
       "      <td>4</td>\n",
       "      <td>138</td>\n",
       "      <td>...</td>\n",
       "      <td>2</td>\n",
       "      <td>-9</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>-9.0</td>\n",
       "      <td>-9.0</td>\n",
       "      <td>name</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>1258</td>\n",
       "      <td>0</td>\n",
       "      <td>54</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>-9</td>\n",
       "      <td>3</td>\n",
       "      <td>150</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>-9</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>-9.0</td>\n",
       "      <td>-9.0</td>\n",
       "      <td>name</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 76 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     id  ccf  age  sex  painloc  painexer  relrest  pncaden  cp  trestbps  \\\n",
       "0  1254    0   40    1        1         0        0       -9   2       140   \n",
       "1  1255    0   49    0        1         0        0       -9   3       160   \n",
       "2  1256    0   37    1        1         0        0       -9   2       130   \n",
       "3  1257    0   48    0        1         1        1       -9   4       138   \n",
       "4  1258    0   54    1        1         0        1       -9   3       150   \n",
       "\n",
       "   ...  rcaprox  rcadist  lvx1  lvx2  lvx3  lvx4  lvf  cathef  junk  name  \n",
       "0  ...       -9       -9     1     1     1     1    1    -9.0  -9.0  name  \n",
       "1  ...       -9       -9     1     1     1     1    1    -9.0  -9.0  name  \n",
       "2  ...       -9       -9     1     1     1     1    1    -9.0  -9.0  name  \n",
       "3  ...        2       -9     1     1     1     1    1    -9.0  -9.0  name  \n",
       "4  ...        1       -9     1     1     1     1    1    -9.0  -9.0  name  \n",
       "\n",
       "[5 rows x 76 columns]"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "OK, first, we know that columns 69 to 76 are junk. Let's drop 'em."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "columns = df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['lvx1', 'lvx2', 'lvx3', 'lvx4', 'lvf', 'cathef', 'junk', 'name'], dtype='object')"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "columns[68:76]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.drop(columns[68:76], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>ccf</th>\n",
       "      <th>age</th>\n",
       "      <th>sex</th>\n",
       "      <th>painloc</th>\n",
       "      <th>painexer</th>\n",
       "      <th>relrest</th>\n",
       "      <th>pncaden</th>\n",
       "      <th>cp</th>\n",
       "      <th>trestbps</th>\n",
       "      <th>...</th>\n",
       "      <th>lmt</th>\n",
       "      <th>ladprox</th>\n",
       "      <th>laddist</th>\n",
       "      <th>diag</th>\n",
       "      <th>cxmain</th>\n",
       "      <th>ramus</th>\n",
       "      <th>om1</th>\n",
       "      <th>om2</th>\n",
       "      <th>rcaprox</th>\n",
       "      <th>rcadist</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>1254</td>\n",
       "      <td>0</td>\n",
       "      <td>40</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>-9</td>\n",
       "      <td>2</td>\n",
       "      <td>140</td>\n",
       "      <td>...</td>\n",
       "      <td>-9</td>\n",
       "      <td>-9</td>\n",
       "      <td>-9</td>\n",
       "      <td>-9</td>\n",
       "      <td>-9</td>\n",
       "      <td>-9</td>\n",
       "      <td>-9</td>\n",
       "      <td>-9</td>\n",
       "      <td>-9</td>\n",
       "      <td>-9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>1255</td>\n",
       "      <td>0</td>\n",
       "      <td>49</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>-9</td>\n",
       "      <td>3</td>\n",
       "      <td>160</td>\n",
       "      <td>...</td>\n",
       "      <td>-9</td>\n",
       "      <td>-9</td>\n",
       "      <td>2</td>\n",
       "      <td>-9</td>\n",
       "      <td>-9</td>\n",
       "      <td>-9</td>\n",
       "      <td>-9</td>\n",
       "      <td>-9</td>\n",
       "      <td>-9</td>\n",
       "      <td>-9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>1256</td>\n",
       "      <td>0</td>\n",
       "      <td>37</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>-9</td>\n",
       "      <td>2</td>\n",
       "      <td>130</td>\n",
       "      <td>...</td>\n",
       "      <td>-9</td>\n",
       "      <td>-9</td>\n",
       "      <td>-9</td>\n",
       "      <td>-9</td>\n",
       "      <td>-9</td>\n",
       "      <td>-9</td>\n",
       "      <td>-9</td>\n",
       "      <td>-9</td>\n",
       "      <td>-9</td>\n",
       "      <td>-9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>1257</td>\n",
       "      <td>0</td>\n",
       "      <td>48</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>-9</td>\n",
       "      <td>4</td>\n",
       "      <td>138</td>\n",
       "      <td>...</td>\n",
       "      <td>-9</td>\n",
       "      <td>2</td>\n",
       "      <td>-9</td>\n",
       "      <td>-9</td>\n",
       "      <td>2</td>\n",
       "      <td>-9</td>\n",
       "      <td>-9</td>\n",
       "      <td>-9</td>\n",
       "      <td>2</td>\n",
       "      <td>-9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>1258</td>\n",
       "      <td>0</td>\n",
       "      <td>54</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>-9</td>\n",
       "      <td>3</td>\n",
       "      <td>150</td>\n",
       "      <td>...</td>\n",
       "      <td>-9</td>\n",
       "      <td>-9</td>\n",
       "      <td>-9</td>\n",
       "      <td>-9</td>\n",
       "      <td>1</td>\n",
       "      <td>-9</td>\n",
       "      <td>-9</td>\n",
       "      <td>-9</td>\n",
       "      <td>1</td>\n",
       "      <td>-9</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 68 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     id  ccf  age  sex  painloc  painexer  relrest  pncaden  cp  trestbps  \\\n",
       "0  1254    0   40    1        1         0        0       -9   2       140   \n",
       "1  1255    0   49    0        1         0        0       -9   3       160   \n",
       "2  1256    0   37    1        1         0        0       -9   2       130   \n",
       "3  1257    0   48    0        1         1        1       -9   4       138   \n",
       "4  1258    0   54    1        1         0        1       -9   3       150   \n",
       "\n",
       "   ...  lmt  ladprox  laddist  diag  cxmain  ramus  om1  om2  rcaprox  rcadist  \n",
       "0  ...   -9       -9       -9    -9      -9     -9   -9   -9       -9       -9  \n",
       "1  ...   -9       -9        2    -9      -9     -9   -9   -9       -9       -9  \n",
       "2  ...   -9       -9       -9    -9      -9     -9   -9   -9       -9       -9  \n",
       "3  ...   -9        2       -9    -9       2     -9   -9   -9        2       -9  \n",
       "4  ...   -9       -9       -9    -9       1     -9   -9   -9        1       -9  \n",
       "\n",
       "[5 rows x 68 columns]"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "inputHidden": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "outputHidden": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "numpy.float64"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "null = df.iloc[0]['pncaden']\n",
    "type(null)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "That is slightly surprising -- Pandas did the numeric conversion automatically"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['id', 'ccf', 'age', 'sex', 'painloc', 'painexer', 'relrest', 'pncaden',\n",
       "       'cp', 'trestbps', 'htn', 'chol', 'smoke', 'cigs', 'years', 'fbs', 'dm',\n",
       "       'famhist', 'restecg', 'ekgmo', 'ekgday', 'ekgyr', 'di', 'pro', 'nit',\n",
       "       'pr', 'diureti', 'proto', 'thaldur', 'thaltime', 'met', 'thalach',\n",
       "       'thalrest', 'tpeakbps', 'tpeakbpd', 'dummy', 'trestbpd', 'exang',\n",
       "       'xhypo', 'oldpeak', 'slope', 'rldv5', 'rldv5e', 'ca', 'restckm',\n",
       "       'exerckm', 'restef', 'restwm', 'exeref', 'exerwm', 'thal', 'thalsev',\n",
       "       'thalpul', 'earlobe', 'cmo', 'cday', 'cyr', 'num', 'lmt', 'ladprox',\n",
       "       'laddist', 'diag', 'cxmain', 'ramus', 'om1', 'om2', 'rcaprox',\n",
       "       'rcadist'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "columns = df.columns\n",
    "columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[columns] = df[columns].replace({-9:np.nan})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "inputHidden": false,
    "outputHidden": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>ccf</th>\n",
       "      <th>age</th>\n",
       "      <th>sex</th>\n",
       "      <th>painloc</th>\n",
       "      <th>painexer</th>\n",
       "      <th>relrest</th>\n",
       "      <th>pncaden</th>\n",
       "      <th>cp</th>\n",
       "      <th>trestbps</th>\n",
       "      <th>...</th>\n",
       "      <th>lmt</th>\n",
       "      <th>ladprox</th>\n",
       "      <th>laddist</th>\n",
       "      <th>diag</th>\n",
       "      <th>cxmain</th>\n",
       "      <th>ramus</th>\n",
       "      <th>om1</th>\n",
       "      <th>om2</th>\n",
       "      <th>rcaprox</th>\n",
       "      <th>rcadist</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>1254.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>40.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2.0</td>\n",
       "      <td>140.0</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>1255.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>49.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3.0</td>\n",
       "      <td>160.0</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>1256.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>37.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2.0</td>\n",
       "      <td>130.0</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>1257.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>48.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>4.0</td>\n",
       "      <td>138.0</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>1258.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>54.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3.0</td>\n",
       "      <td>150.0</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 68 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       id  ccf   age  sex  painloc  painexer  relrest  pncaden   cp  trestbps  \\\n",
       "0  1254.0  0.0  40.0  1.0      1.0       0.0      0.0      NaN  2.0     140.0   \n",
       "1  1255.0  0.0  49.0  0.0      1.0       0.0      0.0      NaN  3.0     160.0   \n",
       "2  1256.0  0.0  37.0  1.0      1.0       0.0      0.0      NaN  2.0     130.0   \n",
       "3  1257.0  0.0  48.0  0.0      1.0       1.0      1.0      NaN  4.0     138.0   \n",
       "4  1258.0  0.0  54.0  1.0      1.0       0.0      1.0      NaN  3.0     150.0   \n",
       "\n",
       "   ...  lmt  ladprox  laddist  diag  cxmain  ramus  om1  om2  rcaprox  rcadist  \n",
       "0  ...  NaN      NaN      NaN   NaN     NaN    NaN  NaN  NaN      NaN      NaN  \n",
       "1  ...  NaN      NaN      2.0   NaN     NaN    NaN  NaN  NaN      NaN      NaN  \n",
       "2  ...  NaN      NaN      NaN   NaN     NaN    NaN  NaN  NaN      NaN      NaN  \n",
       "3  ...  NaN      2.0      NaN   NaN     2.0    NaN  NaN  NaN      2.0      NaN  \n",
       "4  ...  NaN      NaN      NaN   NaN     1.0    NaN  NaN  NaN      1.0      NaN  \n",
       "\n",
       "[5 rows x 68 columns]"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<hr>\n",
    "\n",
    "## Feature Engineering\n",
    "\n",
    "From here, we start to discuss the subtle art of feature engineering and exploratory data analysis. \n",
    "\n",
    "It would be nice to have some kind of baseline for the dataset - it doesn't have to be too elaborate, we just want something to compare with to see if the changes we make to the dataset are beneficial. Unfortunately, we can't build a machine learning model while we have NaNs in it... but dealing with NaNs is one of the factors we'd like the baseline to help control. Hmmm -- a quandry!\n",
    "\n",
    "For now, we will use the simple technique of replacing NaNs with the median of the column. This isn't necessarily the best technique, but it is a simple starting point for this demonstration. The function used below is borrowed from https://pythonhealthcare.org/2018/12/26/115-a-short-function-to-replace-impute-missing-numerical-data-in-pandas-dataframes-with-median-of-column-values/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "def impute_with_median (df):\n",
    "    \"\"\"Iterate through columns of Pandas DataFrame.\n",
    "    Where NaNs exist replace with median\"\"\"\n",
    "    \n",
    "    # Get list of DataFrame column names\n",
    "    cols = list(df)\n",
    "    # Loop through columns\n",
    "    for column in cols:\n",
    "        # Transfer column to independent series\n",
    "        col_data = df[column]\n",
    "        # Look to see if there is any missing numerical data\n",
    "        missing_data = sum(col_data.isna())\n",
    "        if missing_data > 0:\n",
    "            # Get median and replace missing numerical data with median\n",
    "            col_median = col_data.median()\n",
    "            col_data.fillna(col_median, inplace=True)\n",
    "            df[column] = col_data\n",
    "    return df   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>ccf</th>\n",
       "      <th>age</th>\n",
       "      <th>sex</th>\n",
       "      <th>painloc</th>\n",
       "      <th>painexer</th>\n",
       "      <th>relrest</th>\n",
       "      <th>pncaden</th>\n",
       "      <th>cp</th>\n",
       "      <th>trestbps</th>\n",
       "      <th>...</th>\n",
       "      <th>lmt</th>\n",
       "      <th>ladprox</th>\n",
       "      <th>laddist</th>\n",
       "      <th>diag</th>\n",
       "      <th>cxmain</th>\n",
       "      <th>ramus</th>\n",
       "      <th>om1</th>\n",
       "      <th>om2</th>\n",
       "      <th>rcaprox</th>\n",
       "      <th>rcadist</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>1254.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>40.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2.0</td>\n",
       "      <td>140.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>1255.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>49.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3.0</td>\n",
       "      <td>160.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>1256.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>37.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2.0</td>\n",
       "      <td>130.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>1257.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>48.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>4.0</td>\n",
       "      <td>138.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>1258.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>54.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3.0</td>\n",
       "      <td>150.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 68 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       id  ccf   age  sex  painloc  painexer  relrest  pncaden   cp  trestbps  \\\n",
       "0  1254.0  0.0  40.0  1.0      1.0       0.0      0.0      NaN  2.0     140.0   \n",
       "1  1255.0  0.0  49.0  0.0      1.0       0.0      0.0      NaN  3.0     160.0   \n",
       "2  1256.0  0.0  37.0  1.0      1.0       0.0      0.0      NaN  2.0     130.0   \n",
       "3  1257.0  0.0  48.0  0.0      1.0       1.0      1.0      NaN  4.0     138.0   \n",
       "4  1258.0  0.0  54.0  1.0      1.0       0.0      1.0      NaN  3.0     150.0   \n",
       "\n",
       "   ...  lmt  ladprox  laddist  diag  cxmain  ramus  om1  om2  rcaprox  rcadist  \n",
       "0  ...  1.0      1.0      1.0   1.0     1.0    1.0  1.0  1.0      1.0      1.0  \n",
       "1  ...  1.0      1.0      2.0   1.0     1.0    1.0  1.0  1.0      1.0      1.0  \n",
       "2  ...  1.0      1.0      1.0   1.0     1.0    1.0  1.0  1.0      1.0      1.0  \n",
       "3  ...  1.0      2.0      1.0   1.0     2.0    1.0  1.0  1.0      2.0      1.0  \n",
       "4  ...  1.0      1.0      1.0   1.0     1.0    1.0  1.0  1.0      1.0      1.0  \n",
       "\n",
       "[5 rows x 68 columns]"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = impute_with_median(df)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If we were really concerned about accuracy, we would do before and after graphs of normality (for example) and make sure the the graph's profile didn't change. As it is, that `pncaden` column looks fishy. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(df.pncaden) - df.pncaden.isnull().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As I thought, `pncaden` has no data. We should probably make sure there aren't any more like that and drop them."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "drop_cols = [c for c in df.columns if len(df[c]) - df[c].isnull().sum() == 0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.drop(drop_cols, axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Fast check for any NaNs\n",
    "df.isnull().values.any()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>ccf</th>\n",
       "      <th>age</th>\n",
       "      <th>sex</th>\n",
       "      <th>painloc</th>\n",
       "      <th>painexer</th>\n",
       "      <th>relrest</th>\n",
       "      <th>cp</th>\n",
       "      <th>trestbps</th>\n",
       "      <th>htn</th>\n",
       "      <th>...</th>\n",
       "      <th>lmt</th>\n",
       "      <th>ladprox</th>\n",
       "      <th>laddist</th>\n",
       "      <th>diag</th>\n",
       "      <th>cxmain</th>\n",
       "      <th>ramus</th>\n",
       "      <th>om1</th>\n",
       "      <th>om2</th>\n",
       "      <th>rcaprox</th>\n",
       "      <th>rcadist</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>1254.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>40.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>140.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>1255.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>49.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>160.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>1256.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>37.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>130.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>1257.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>48.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>138.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>1258.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>54.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>150.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 66 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       id  ccf   age  sex  painloc  painexer  relrest   cp  trestbps  htn  \\\n",
       "0  1254.0  0.0  40.0  1.0      1.0       0.0      0.0  2.0     140.0  0.0   \n",
       "1  1255.0  0.0  49.0  0.0      1.0       0.0      0.0  3.0     160.0  1.0   \n",
       "2  1256.0  0.0  37.0  1.0      1.0       0.0      0.0  2.0     130.0  0.0   \n",
       "3  1257.0  0.0  48.0  0.0      1.0       1.0      1.0  4.0     138.0  0.0   \n",
       "4  1258.0  0.0  54.0  1.0      1.0       0.0      1.0  3.0     150.0  0.0   \n",
       "\n",
       "   ...  lmt  ladprox  laddist  diag  cxmain  ramus  om1  om2  rcaprox  rcadist  \n",
       "0  ...  1.0      1.0      1.0   1.0     1.0    1.0  1.0  1.0      1.0      1.0  \n",
       "1  ...  1.0      1.0      2.0   1.0     1.0    1.0  1.0  1.0      1.0      1.0  \n",
       "2  ...  1.0      1.0      1.0   1.0     1.0    1.0  1.0  1.0      1.0      1.0  \n",
       "3  ...  1.0      2.0      1.0   1.0     2.0    1.0  1.0  1.0      2.0      1.0  \n",
       "4  ...  1.0      1.0      1.0   1.0     1.0    1.0  1.0  1.0      1.0      1.0  \n",
       "\n",
       "[5 rows x 66 columns]"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***\n",
    "\n",
    "## Baseline\n",
    "\n",
    "\n",
    "According to our documentation, feature \\#58, `num`, is the target variable.\n",
    "\n",
    "Briefly:\n",
    "\n",
    "* We'll do a 70 / 30 train-test split\n",
    "* Train a RandomForestClassifier\n",
    "* Run & evaluate accuracy on the test data\n",
    "\n",
    "One of the interesting abilities of the Random Forest is that it can tell you the importance of each feature in its decision-making process. After the baseline, we can use that to tailor our feature engineering."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import RandomForestClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = df.num\n",
    "x = df.drop(['id','ccf','dummy','num'], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train,x_test,y_train,y_test=train_test_split(x,y,test_size=0.3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf=RandomForestClassifier(n_estimators=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RandomForestClassifier(bootstrap=True, class_weight=None, criterion='gini',\n",
       "                       max_depth=None, max_features='auto', max_leaf_nodes=None,\n",
       "                       min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "                       min_samples_leaf=1, min_samples_split=2,\n",
       "                       min_weight_fraction_leaf=0.0, n_estimators=100,\n",
       "                       n_jobs=None, oob_score=False, random_state=None,\n",
       "                       verbose=0, warm_start=False)"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf.fit(x_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred=clf.predict(x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.8064516129032258\n"
     ]
    }
   ],
   "source": [
    "print(\"Accuracy:\",metrics.accuracy_score(y_test, y_pred)) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Feature importance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Feature ranking:\n",
      "1. feature rcaprox (0.08310086475091256)\n",
      "2. feature ladprox (0.07563300043671184)\n",
      "3. feature cxmain (0.06982430392689183)\n",
      "4. feature lmt (0.03994738411041206)\n",
      "5. feature oldpeak (0.03203293319437019)\n",
      "6. feature laddist (0.03106306532851476)\n",
      "7. feature painexer (0.029606070554334694)\n",
      "8. feature chol (0.02847214294390067)\n",
      "9. feature thaldur (0.026753280906107083)\n",
      "10. feature thalach (0.026173796367527157)\n",
      "11. feature age (0.026048392387691386)\n",
      "12. feature proto (0.025117739512824592)\n",
      "13. feature thalrest (0.02370155624316311)\n",
      "14. feature cday (0.02291541451138018)\n",
      "15. feature thaltime (0.022455955429482886)\n",
      "16. feature ekgday (0.02227099437428657)\n",
      "17. feature om1 (0.021986278994432295)\n",
      "18. feature trestbps (0.02156336564080962)\n",
      "19. feature rcadist (0.021542970857405013)\n",
      "20. feature cmo (0.019835978072476543)\n",
      "21. feature met (0.019783122809385396)\n",
      "22. feature rldv5e (0.01927727342527005)\n",
      "23. feature trestbpd (0.018731403084239772)\n",
      "24. feature tpeakbps (0.01845992148963829)\n",
      "25. feature cp (0.01845722478297598)\n",
      "26. feature rldv5 (0.017927656284146828)\n",
      "27. feature exang (0.017545158154068062)\n",
      "28. feature tpeakbpd (0.017085680010141862)\n",
      "29. feature ekgmo (0.016096087391799702)\n",
      "30. feature years (0.014266979074988582)\n",
      "31. feature cyr (0.014019735376362632)\n",
      "32. feature ekgyr (0.012497538552154295)\n",
      "33. feature cigs (0.010118097789013538)\n",
      "34. feature ramus (0.009749920186823248)\n",
      "35. feature restecg (0.009383063880547248)\n",
      "36. feature diag (0.008958966558142037)\n",
      "37. feature nit (0.00844117339934233)\n",
      "38. feature pr (0.008330001203268295)\n",
      "39. feature htn (0.007861030499239035)\n",
      "40. feature thalsev (0.006460431079594675)\n",
      "41. feature slope (0.006380306911832361)\n",
      "42. feature pro (0.005880608778226729)\n",
      "43. feature relrest (0.005853186492895523)\n",
      "44. feature fbs (0.005251766265969728)\n",
      "45. feature smoke (0.004145406556073988)\n",
      "46. feature diureti (0.003945212849778494)\n",
      "47. feature om2 (0.0035288238665643996)\n",
      "48. feature thal (0.003233054633778518)\n",
      "49. feature famhist (0.003202768847486122)\n",
      "50. feature sex (0.0023887298777999443)\n",
      "51. feature xhypo (0.0019304420831082686)\n",
      "52. feature restef (0.0019040350882586002)\n",
      "53. feature restwm (0.0018219408229361899)\n",
      "54. feature painloc (0.0016322663456871625)\n",
      "55. feature thalpul (0.0015575694111063308)\n",
      "56. feature di (0.0013166341663357892)\n",
      "57. feature ca (0.0013063384246734227)\n",
      "58. feature exeref (0.0004353643908916314)\n",
      "59. feature exerwm (0.0004303700487669723)\n",
      "60. feature dm (0.00035922056305322497)\n",
      "61. feature exerckm (0.0)\n",
      "62. feature earlobe (0.0)\n"
     ]
    }
   ],
   "source": [
    "features = x_train.columns\n",
    "importances = clf.feature_importances_\n",
    "std = np.std([tree.feature_importances_ for tree in clf.estimators_],\n",
    "             axis=0)\n",
    "indices = np.argsort(importances)[::-1]\n",
    "\n",
    "# Print the feature ranking\n",
    "print(\"Feature ranking:\")\n",
    "\n",
    "for f in range(x_train.shape[1]):\n",
    "    print(f\"{f + 1}. feature {features[indices[f]]} ({importances[indices[f]]})\" )\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "35 / 62 scored higher than 0.9% importance\n"
     ]
    }
   ],
   "source": [
    "# Only choose 1% importance or higher\n",
    "\n",
    "big_features = []\n",
    "for f in range(x_train.shape[1]):\n",
    "    if importances[indices[f]] > 0.009:\n",
    "        big_features.append(features[indices[f]])\n",
    "#     print(f\"{f + 1}. feature {features[indices[f]]} ({importances[indices[f]]})\" )\n",
    "\n",
    "print(f'{len(big_features)} / {len(features)} scored higher than 0.9% importance')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***\n",
    "\n",
    "## Normalizing and choosing columns\n",
    "\n",
    "We saw above that 35 of the features have more than 1% importance, but 1% is a pretty low bar. We also know from the documentation that only 14 of the features are used in the published studies. It might be nice to check if those 14 are in the \"important\" list.\n",
    "\n",
    "**But wait! There's more!**\n",
    "\n",
    "We are going to do two more things: \n",
    "\n",
    "1. We are going to use sklearn's preprocessing module to scale the data. This should help normalize it.\n",
    "2. We are going to add a column of random numbers as a control. When choosing columns for importance, we would like our choices to score better than random data!\n",
    "\n",
    "Also note that normally we would have had to change categorical data into some numerical representation, but in this case, the data already came in that form.\n",
    "\n",
    "**Non-categorical columns (for scaling/normalizing):** age, trestbps, htn, chol, cigs, years, thaldur, thaltime, met, thalach, thalrest, tpeakbps, tpeakbpd, trestbpd, oldpeak, rldv5, rldv5e, restef, exeref, exerwm, cmo, cday, cyr, lmt, ladprox, laddist, diag, cxmain, ramus, om1, om2, rcaprox, rcadist\n",
    "\n",
    "**remove:** exerckm, thalsev, thalpul, earlobe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remember, x is our data set\n",
    "x = x.drop(['exerckm', 'thalsev', 'thalpul', 'earlobe'], axis=1)\n",
    "x_norm_cols = ['age', 'trestbps', 'htn', 'chol', 'cigs', 'years', 'thaldur', 'thaltime', 'met', 'thalach', 'thalrest', 'tpeakbps', 'tpeakbpd', 'trestbpd', 'oldpeak', 'rldv5', 'rldv5e', 'restef', 'exeref', 'exerwm', 'cmo', 'cday', 'cyr', 'lmt', 'ladprox', 'laddist', 'diag', 'cxmain', 'ramus', 'om1', 'om2', 'rcaprox', 'rcadist']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import MinMaxScaler\n",
    "\n",
    "scaler = MinMaxScaler(feature_range=(0, 1))\n",
    "\n",
    "# d = pd.DataFrame({'A': [0, 1, 2, 3, np.nan, 3, 2]})\n",
    "# null_index = d['A'].isnull()\n",
    "# d.loc[~null_index, ['A']] = scaler.fit_transform(d.loc[~null_index, ['A']])\n",
    "\n",
    "\n",
    "x[x_norm_cols] = scaler.fit_transform(x[x_norm_cols])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>age</th>\n",
       "      <th>sex</th>\n",
       "      <th>painloc</th>\n",
       "      <th>painexer</th>\n",
       "      <th>relrest</th>\n",
       "      <th>cp</th>\n",
       "      <th>trestbps</th>\n",
       "      <th>htn</th>\n",
       "      <th>chol</th>\n",
       "      <th>smoke</th>\n",
       "      <th>...</th>\n",
       "      <th>lmt</th>\n",
       "      <th>ladprox</th>\n",
       "      <th>laddist</th>\n",
       "      <th>diag</th>\n",
       "      <th>cxmain</th>\n",
       "      <th>ramus</th>\n",
       "      <th>om1</th>\n",
       "      <th>om2</th>\n",
       "      <th>rcaprox</th>\n",
       "      <th>rcadist</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>0.244898</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.70</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.479270</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.006173</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>0.428571</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.80</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.298507</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.006173</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.183673</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.65</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.469320</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.006173</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.408163</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0.69</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.354892</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.006173</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0.530612</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.75</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.354892</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.006173</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 58 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        age  sex  painloc  painexer  relrest   cp  trestbps  htn      chol  \\\n",
       "0  0.244898  1.0      1.0       0.0      0.0  2.0      0.70  0.0  0.479270   \n",
       "1  0.428571  0.0      1.0       0.0      0.0  3.0      0.80  1.0  0.298507   \n",
       "2  0.183673  1.0      1.0       0.0      0.0  2.0      0.65  0.0  0.469320   \n",
       "3  0.408163  0.0      1.0       1.0      1.0  4.0      0.69  0.0  0.354892   \n",
       "4  0.530612  1.0      1.0       0.0      1.0  3.0      0.75  0.0  0.354892   \n",
       "\n",
       "   smoke  ...       lmt  ladprox  laddist  diag  cxmain  ramus  om1  om2  \\\n",
       "0    1.0  ...  0.006173      0.0      0.0   0.0     0.0    0.0  0.0  0.0   \n",
       "1    1.0  ...  0.006173      0.0      1.0   0.0     0.0    0.0  0.0  0.0   \n",
       "2    1.0  ...  0.006173      0.0      0.0   0.0     0.0    0.0  0.0  0.0   \n",
       "3    1.0  ...  0.006173      1.0      0.0   0.0     1.0    0.0  0.0  0.0   \n",
       "4    1.0  ...  0.006173      0.0      0.0   0.0     0.0    0.0  0.0  0.0   \n",
       "\n",
       "   rcaprox  rcadist  \n",
       "0      0.0      0.0  \n",
       "1      0.0      0.0  \n",
       "2      0.0      0.0  \n",
       "3      1.0      0.0  \n",
       "4      0.0      0.0  \n",
       "\n",
       "[5 rows x 58 columns]"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, our random column. First, we need a random seed -- just a number to be used in the creation of the \"random\" numbers. Then we'll add the column."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "x['random'] = np.random.normal(0.0, 1.0, size=x.shape[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "OK, let's check our accuracy again and see where the random data falls."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train,x_test,y_train,y_test=train_test_split(x,y,test_size=0.3)\n",
    "clf=RandomForestClassifier(n_estimators=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RandomForestClassifier(bootstrap=True, class_weight=None, criterion='gini',\n",
       "                       max_depth=None, max_features='auto', max_leaf_nodes=None,\n",
       "                       min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "                       min_samples_leaf=1, min_samples_split=2,\n",
       "                       min_weight_fraction_leaf=0.0, n_estimators=100,\n",
       "                       n_jobs=None, oob_score=False, random_state=None,\n",
       "                       verbose=0, warm_start=False)"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf.fit(x_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred=clf.predict(x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.7795698924731183\n"
     ]
    }
   ],
   "source": [
    "print(\"Accuracy:\",metrics.accuracy_score(y_test, y_pred)) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So, our accuracy increased. Not bad but I'm sure we could get better. \n",
    "\n",
    "Let's have a look at important columns:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Feature ranking:\n",
      "1. feature ladprox   \t6.32%\n",
      "2. feature rcaprox   \t6.27%\n",
      "3. feature cxmain   \t5.96%\n",
      "4. feature lmt   \t4.23%\n",
      "5. feature laddist   \t4.13%\n",
      "6. feature chol   \t3.52%\n",
      "7. feature proto   \t3.35%\n",
      "8. feature age   \t3.23%\n",
      "9. feature painexer   \t2.86%\n",
      "10. feature exang   \t2.76%\n",
      "11. feature random   \t2.73% <==\n",
      "12. feature thaldur   \t2.73%\n",
      "13. feature oldpeak   \t2.67%\n",
      "14. feature thalrest   \t2.53%\n",
      "15. feature met   \t2.45%\n",
      "16. feature trestbps   \t2.40%\n",
      "17. feature cday   \t2.27%\n",
      "18. feature rcadist   \t2.22%\n",
      "19. feature thalach   \t2.19%\n",
      "20. feature ekgday   \t2.16%\n",
      "21. feature tpeakbps   \t2.05%\n",
      "22. feature om1   \t2.01%\n",
      "23. feature thaltime   \t1.96%\n",
      "24. feature cmo   \t1.93%\n",
      "25. feature rldv5   \t1.85%\n",
      "26. feature cp   \t1.80%\n",
      "27. feature rldv5e   \t1.63%\n",
      "28. feature trestbpd   \t1.60%\n",
      "29. feature ekgmo   \t1.59%\n",
      "30. feature relrest   \t1.47%\n",
      "31. feature tpeakbpd   \t1.46%\n",
      "32. feature years   \t1.15%\n",
      "33. feature cyr   \t1.05%\n",
      "34. feature ekgyr   \t1.04%\n",
      "35. feature restecg   \t0.90%\n",
      "36. feature ramus   \t0.83%\n",
      "37. feature cigs   \t0.78%\n",
      "38. feature pr   \t0.77%\n",
      "39. feature diag   \t0.75%\n",
      "40. feature nit   \t0.72%\n",
      "41. feature slope   \t0.66%\n",
      "42. feature htn   \t0.63%\n",
      "43. feature fbs   \t0.58%\n",
      "44. feature pro   \t0.54%\n",
      "45. feature diureti   \t0.46%\n",
      "46. feature thal   \t0.44%\n",
      "47. feature smoke   \t0.39%\n",
      "48. feature sex   \t0.34%\n",
      "49. feature famhist   \t0.30%\n",
      "50. feature om2   \t0.27%\n",
      "51. feature restef   \t0.27%\n",
      "52. feature restwm   \t0.20%\n",
      "53. feature painloc   \t0.19%\n",
      "54. feature xhypo   \t0.12%\n",
      "55. feature ca   \t0.09%\n",
      "56. feature dm   \t0.08%\n",
      "57. feature di   \t0.08%\n",
      "58. feature exerwm   \t0.03%\n",
      "59. feature exeref   \t0.02%\n"
     ]
    }
   ],
   "source": [
    "features = x_train.columns\n",
    "importances = clf.feature_importances_\n",
    "std = np.std([tree.feature_importances_ for tree in clf.estimators_],\n",
    "             axis=0)\n",
    "indices = np.argsort(importances)[::-1]\n",
    "\n",
    "# Save the feature ranking to a list for later use\n",
    "# and print it on the screen\n",
    "\n",
    "feature_rank = []\n",
    "print(\"Feature ranking:\")\n",
    "\n",
    "for f in range(x_train.shape[1]):\n",
    "    feature = f\"{f + 1}. feature {features[indices[f]]}   \\t{importances[indices[f]] * 100 :.2f}%\"\n",
    "    if 'random' in features[indices[f]]:\n",
    "        feature += \" <==\"\n",
    "    print(feature)\n",
    "    feature_rank.append([features[indices[f]], importances[indices[f]]] )\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**WOW!!** The random data came in at number 11? So the other 48 features were *literally* less useful than random data.\n",
    "\n",
    "***\n",
    "\n",
    "There is still more we could do, including looking at pair plots and correlation matrices, but we'll leave that for next week. Let's save the dataset as we have it right now, then next week we can load it back in and use some visualization tools to help us analyze the data. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add the target column back in\n",
    "x['num'] = y\n",
    "x.to_csv('heart_disease_formatted.csv', index=None, header=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv\n",
    "\n",
    "with open('feature_rank.csv', 'w') as writeFile:\n",
    "    writer = csv.writer(writeFile)\n",
    "    writer.writerows(feature_rank)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Completely random, non-lesson related libraries to try..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Pandas Extensions\n",
    "\n",
    "https://github.com/mouradmourafiq/pandas-summary\n",
    "\n",
    "\n",
    "\n",
    "https://medium.com/dunder-data/from-pandas-to-scikit-learn-a-new-exciting-workflow-e88e2271ef62"
   ]
  }
 ],
 "metadata": {
  "kernel_info": {
   "name": "python3"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  },
  "nteract": {
   "version": "0.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
