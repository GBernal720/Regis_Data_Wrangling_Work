{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Week 4 - SQL and NoSQL Databases\n",
    "\n",
    "**Outline:**<br>\n",
    "\n",
    "* (Two) Types\n",
    "    * Relational - SQL\n",
    "        * Using the Dataset Library\n",
    "    * Not Only SQL - NoSQL\n",
    "        * TinyDB\n",
    "* Use Case -- working with emails\n",
    "    * Data set - Enron Corpus\n",
    "        * Background info - email format & Python\n",
    "        * Background info - reading directory structure and listing files\n",
    "        * Background info - dataclasses\n",
    "        * Background info - multithreading and multiprocessing\n",
    "    * Case 1 - Relational DB (SQLite3)\n",
    "    * Case 2 - NoSQL (TinyDB)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## (Two) Types\n",
    "\n",
    "Formally, there are several different types of database. Relational, NoSQL, Graph, Object, Data Warehouse, etc. They all exist to provide organization and rapid access to data. Although it can be fun to study and use some of the more esoteric types (yes, I said \"fun.\" I'm a wild man on Saturday night, believe me), we will only be looking at relational and NoSQL as being the two most common types in wide use today.\n",
    "\n",
    "### Relational - SQL\n",
    "\n",
    "You had a bit of an introduction to SQL and relational databases in Week 2. This week we will build on that knowledge by creating simple database tables to handle emails. \n",
    "\n",
    "The term \"relational\" comes from a research paper by E. F. Cobb in 1970. \"A relational Model for Large Shared Data Banks\" described a bunch of features a relational data store should have (12 of them) but no commercial database conforms to that standard. We generally recognize a relational data base as a *table-based* system where rows are discreet data points (a person, an order item, an inventory item, etc.) and columns are the attributes or details about the entry, as well as a set of operations that relate tables to each other (more on this later). \n",
    "<hr>\n",
    "Reference: Wikipedia - Relational Database, https://en.wikipedia.org/wiki/Relational_database, accessed 10/14/2019."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In Week 2, we saw an employees table related to a departments table. \n",
    "\n",
    "**employees**\n",
    "\n",
    "emp_id | emp_name | dept_id\n",
    "--|-----|-----------\n",
    "1 | Tom | 1\n",
    "2 | Mary | 2\n",
    "3 | John | 3\n",
    "4 | Tim | 1\n",
    "5 | Jenny | \n",
    "\n",
    "NOTE: Jenny is a new hire not assigned a department yet.<br>\n",
    "**departments**\n",
    "\n",
    "dept_id | dept_name\n",
    "--------|----------\n",
    "1 | HR\n",
    "2 | Development\n",
    "3 | Marketing\n",
    "\n",
    "One important feature of these tables is the \"id\" column on the left side (emp_id and dept_id). **Every** table will have some way to make every row unique. Since we cannot guarantee there will *never* be repeats, we add a synthetic \"id\" column that uniquely identies each row. That way, even if there are two John Smiths, we have at least one way to single each one out. In this case, emp_id is the **primary key** in the employee table. Similarly, dept_id is the primary key of the departments table. \n",
    "\n",
    "You'll also notice that the employee table has a column called **dept_id**. This is because dept_id is a **foreign key** in the employee table. Instead of writing (and repeating) the department name in the employees table, we put in a reference to the departments table. There are a variety of reasons to do this referencing including, \n",
    "\n",
    "* Making tables smaller and more space-efficient,\n",
    "* Making data easier to correct and less error prone\n",
    "\n",
    "In this case, that foreign key is what *relates* those two tables to each other. \n",
    "\n",
    "As mentioned in Week 2, a well-designed relational database will have safeguards built into the tables that keep us from doing bad things. These safeguards are called *constraints* and can include conditions like,\n",
    "\n",
    "* Insuring a column's value is unique (for example, the primary key)\n",
    "* Insuring NULL cannot be inserted\n",
    "* Placing conditions on updates and deletes (usually due to relations)\n",
    "* etc.\n",
    "\n",
    "It should be noted that in the interest of simplicity, neither our employee database nor the stock price database from week 2 had any constraints. \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Using the Dataset library\n",
    "<div class=\"alert alert-block alert-info\">\n",
    "<b>Helpful Hint::</b> See the Week 2 FTE for instructions and examples using Dataset. You will get the opportunity to work more with a relational database using Dataset to store emails later in the Use Cases.\n",
    "</div>\n",
    "\n",
    "<hr>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Not Only SQL - NoSQL Databases\n",
    "\n",
    "NoSQL databases are many times used to store data that does not easily fit into the structure that relational databases require. Many times we call this **\"unstructured data.\"** \n",
    "\n",
    "Although many kinds of NoSQL database exist, four major types are often seen:\n",
    "\n",
    "* __Document__ - Stores semi-structured JSON documents. Very popular with web applications storing unique documents like catalogs or user profiles that evolve over time. MongoDB and CouchBase are two popular examples.\n",
    "* __Graph__ - Data is stored in record-like nodes which are interconnected by lines called edges that represent relationships between nodes. Graph databases these relationships in a more flexible and dynamic way than traditional relational databases. Examples include Neo4j and IBM Graph.\n",
    "* __Key-value__ - Store data much like a Python dictionary. Every value is accessed by some unique key and values can be complex objects like lists, documents, files, etc. Redis and Riak are popular examples. \n",
    "* __Wide column__ - Records in tables are organized by column instead of by row. This allows for very fast access to large volumes of data. Google Big Table, Cassandra, and HBase are examples."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img align=\"right\" style=\"padding-right:10px;\" src=\"figures_wk4/tinydb_logo.png\" width=300><br>\n",
    "## TinyDB\n",
    "<div style=\"text-align: right\">\n",
    "https://tinydb.readthedocs.io/en/latest/intro.html\n",
    "</div>\n",
    "<br>\n",
    "Our investigation will use the TinyDB document database. TinyDB is a pure-Python implementation (meaning we have to install a Python library but not a full DB server) that closely resembles MongoDB, the most popular database for web and ecommerce systems. \n",
    "\n",
    "\n",
    "### Using TinyDB\n",
    "\n",
    "As always, we have to import the library and connect to the database, which, in this case, is a file much like SQLite.\n",
    "\n",
    "```\n",
    "from tinydb import TinyDB, Query\n",
    "db = TinyDB('db.json')\n",
    "```\n",
    "\n",
    "TinyDB stores data in a JSON file (HA! You thought all that JSON in Week 1 was a waste of time!). In the case above, the file is \"db.json\" and the variable `db` is our connection object. \n",
    "\n",
    "TinyDB's `insert()` method accepts a dictionary as the document to be inserted into the database. A simple example:\n",
    "\n",
    "```\n",
    "db.insert({'type': 'apple', 'count': 7})\n",
    "db.insert({'type': 'peach', 'count': 3})\n",
    "```\n",
    "\n",
    "You can retrieve all documents in the database by \n",
    "\n",
    "`db.all()`\n",
    "\n",
    "which will give us a list containing the documents:\n",
    "\n",
    "`[{'count': 7, 'type': 'apple'}, {'count': 3, 'type': 'peach'}]`\n",
    "\n",
    "We can iterate over the stored documents:\n",
    "```\n",
    "for item in db:\n",
    "    print(item)\n",
    "    \n",
    "{'count': 7, 'type': 'apple'}\n",
    "{'count': 3, 'type': 'peach'}\n",
    "```\n",
    "\n",
    "To search for specific documents, you need to make a `Query()` object:\n",
    "```\n",
    "Fruit = Query()\n",
    "db.search(Fruit.type == 'peacth')\n",
    "```\n",
    "\n",
    "gives:\n",
    "\n",
    "`[{'count': 3, 'type': 'peach'}]`\n",
    "\n",
    "and\n",
    "\n",
    "`db.search(Fruit.count > 5)`\n",
    "\n",
    "gives:\n",
    "\n",
    "`[{'count': 7, 'type': 'apple'}]`\n",
    "\n",
    "\n",
    "Let's test this theory with running code.\n",
    "\n",
    "\n",
    "References:<br>\n",
    "https://aws.amazon.com/nosql/document/<br>\n",
    "https://searchdatamanagement.techtarget.com/definition/NoSQL-Not-Only-SQL<br>\n",
    "https://tinydb.readthedocs.io/en/latest/intro.html<br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-info\">\n",
    "<b>Helpful Hint::</b> As we saw in week 3, we can install TinyDB from inside our notebook. If you already have it installed, pip will gracefully let you know.\n",
    "Added the following cell too\n",
    "</div>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: tinydb in /opt/anaconda3/lib/python3.7/site-packages (3.15.1)\r\n"
     ]
    }
   ],
   "source": [
    "!pip install tinydb"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-warning\">\n",
    "<b>Note:</b> If data/db.json already exists in your local directory, the counts below will not match. You can safely delete this file and TinyDB will recreate it as needed. However, if you decided to not delete this file, TinyDB will simply append to the existing file.\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tinydb import TinyDB, Query\n",
    "db = TinyDB('data_wk4/db.json')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'type': 'apple', 'count': 7}, {'type': 'peach', 'count': 3}]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "db.insert({'type': 'apple', 'count': 7})\n",
    "db.insert({'type': 'peach', 'count': 3})\n",
    "db.all()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'type': 'apple', 'count': 7}\n",
      "{'type': 'peach', 'count': 3}\n"
     ]
    }
   ],
   "source": [
    "for item in db:\n",
    "    print(item)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Notice the `Query()` object we create below, called Fruit, uses the `'type'` key to do the search."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'type': 'peach', 'count': 3}]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Fruit = Query()\n",
    "db.search(Fruit.type == 'peach')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Similarly, we can use the `'count'` key and conditional operators:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'type': 'apple', 'count': 7}]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "db.search(Fruit.count > 5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Just like in a relational database, we can update and delete (remove)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'type': 'apple', 'count': 10}, {'type': 'peach', 'count': 3}]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "db.update({'count': 10}, Fruit.type == 'apple')\n",
    "db.all()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'type': 'apple', 'count': 10}]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "db.remove(Fruit.count < 5)\n",
    "db.all()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is just the very tip of the iceberg. We will see more in the Use Case 2 below.\n",
    "<hr>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Use Case -- Working with Emails\n",
    "\n",
    "On a high level, emails represent interesting opportunities for text analytics and text processing but before we can do the high-level stuff, we might want to do some preprocessing on the messages. For example, if we want to use the \"To:\" field or \"From:\" field as part of the filter of our WHERE clause, we really should pull those parts off of the email and store them in their own column. Really, to do it right, we would probably have separate tables for email addresses and have them related, but that design and coding is outside the scope of this class. I'll leave that as extra-credit for you students. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data set -- Enron Corpus\n",
    "\n",
    "Enron was a Fortune 500 energy supply company in Houston, Texas that filed for bankruptcy in 2001 after years of corporate fraud and \"creative\" accounting. It sent ripples through the business world and was responsible for laws being enacted as well as the closing of *Arthur Anderson*, a very large and famous accounting firm (Wikipedia).\n",
    "\n",
    "The emails in the corpus were saved from the litigation process, errors corrected, in some cases anonymized, and made public for research use. The first reference link below describes the corpus and its history and handling in detail with links to even more detail. Students are encouraged to at least skim the reference links for more info. \n",
    "\n",
    "The corpus itself consists of approximately 500,000 emails, arranged in a folder structure by name. Each user's folder has Inbox, Sent, Trash, etc. folders inside, just as Microsoft Outlook creates. \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-success\">\n",
    "<b>Installation - Enron Corpus::</b> <br>\n",
    "    <b>**Please download the compressed file from WorldClass that contains this corpus**</b><br>\n",
    "If you have difficulties retrieving this file, you can find a copy at: https://www.cs.cmu.edu/~enron/enron_mail_20150507.tar.gz\n",
    "\n",
    "**Windows users:** 7-zip is an excellent compression program capable of handing .tar.gz files.\n",
    "\n",
    "To facilitate data organization (and sneakily introduce an important computer-sciency concept), we will construct an email **dataclass** a new feature of Python 3.7. See below for information on dataclasses.\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "Also, due to the sheer number of emails to read and process, we will introduce the concept of **parallel processing** -- an important concept in the \"real world\" to speed up data processing. See the section on multithreading and multiprocessing below for more info. \n",
    "\n",
    "<hr>\n",
    "\n",
    "*Reference:*\n",
    "\n",
    "https://www.cs.cmu.edu/~enron/\n",
    "https://en.wikipedia.org/wiki/Enron\n",
    "\n",
    "<hr>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Background info - email format & Python\n",
    "\n",
    "Python's email library is powerful to build a full-fledged email program, capable of handling different formats and attachments. We won't need anything *that* powerful, but we do need the ability to read email messages from disk and properly identify the different parts of a message. For that we will use the email library's `parser` class. \n",
    "\n",
    "Email messages have several parts and the ability of email programs to properly recognize those parts are what insures proper routing of messages. For the Enron data, we are concerned with:\n",
    "\n",
    "* From:\n",
    "* To:\n",
    "* Subject:\n",
    "* Body:\n",
    "\n",
    "fields. We will ignore any attachments, if they exist.\n",
    "<hr>\n",
    "\n",
    "Sometimes I wonder about the Python devs. I found this in the official Python 3.8 documentation:\n",
    "\n",
    "\n",
    "<img align=\"center\" style=\"padding-right:10px;\" src=\"figures_wk4/imaginary.png\" width=600><br><br>\n",
    "\n",
    "<hr>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Background info - reading directory structure and listing files\n",
    "\n",
    "To be able to process 500,000 emails in multiple directories, we will need the ability to read and \"walk\" the computer's directory and file structure. The \"tarball\" of emails uncompresses into a folder called `maildir`. Mine is in my `~/Code/MachineLearning` directory:\n",
    "\n",
    "<img align=\"center\" style=\"padding-right:10px;\" src=\"figures_wk4/maildir.png\" width=600><br><br>\n",
    "\n",
    "Inside you can see the names of the email users. Inside each of those is a fairly standard list of folders:<br>\n",
    "\n",
    "<img align=\"center\" style=\"padding-right:10px;\" src=\"figures_wk4/allen-p.png\" width=600><br><br>\n",
    "\n",
    "At this point, I'm assuming you have downloaded the corpus and can follow along.\n",
    "<hr>\n",
    "\n",
    "First, let's make sure we can access the directories. Notice that the variable rootdir below is pointing to my file structure.  You will need to adjust this variable to match your local directory structure.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "# Concatenating strings to build directories\n",
    "# Like we built file names in FTE Week 2\n",
    "#rootdir = \"/Users/mbusch/Code/MachineLearning/maildir\"\n",
    "rootdir = \"/Users/cpearson/Regis/Faculty/MSDE621/FTE_Content/Week4/maildir\"\n",
    "allen = rootdir + '/allen-p'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/Users/cpearson/Regis/Faculty/MSDE621/FTE_Content/Week4/maildir/allen-p ['notes_inbox', 'deleted_items', 'inbox', 'discussion_threads', 'contacts', 'sent_items', 'sent', '_sent_mail', 'straw', 'all_documents'] 0\n",
      "/Users/cpearson/Regis/Faculty/MSDE621/FTE_Content/Week4/maildir/allen-p/notes_inbox [] 48\n",
      "/Users/cpearson/Regis/Faculty/MSDE621/FTE_Content/Week4/maildir/allen-p/deleted_items [] 361\n",
      "/Users/cpearson/Regis/Faculty/MSDE621/FTE_Content/Week4/maildir/allen-p/inbox [] 66\n",
      "/Users/cpearson/Regis/Faculty/MSDE621/FTE_Content/Week4/maildir/allen-p/discussion_threads [] 412\n",
      "/Users/cpearson/Regis/Faculty/MSDE621/FTE_Content/Week4/maildir/allen-p/contacts [] 2\n",
      "/Users/cpearson/Regis/Faculty/MSDE621/FTE_Content/Week4/maildir/allen-p/sent_items [] 345\n",
      "/Users/cpearson/Regis/Faculty/MSDE621/FTE_Content/Week4/maildir/allen-p/sent [] 562\n",
      "/Users/cpearson/Regis/Faculty/MSDE621/FTE_Content/Week4/maildir/allen-p/_sent_mail [] 602\n",
      "/Users/cpearson/Regis/Faculty/MSDE621/FTE_Content/Week4/maildir/allen-p/straw [] 8\n",
      "/Users/cpearson/Regis/Faculty/MSDE621/FTE_Content/Week4/maildir/allen-p/all_documents [] 628\n"
     ]
    }
   ],
   "source": [
    "# I'm only going to look at the allen-p directory to limit output\n",
    "for directory, subdirectory, filenames in os.walk(allen):\n",
    "    print(directory, subdirectory, len(filenames))\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The `os.walk()` function gives us each directory, a listing of it's subdirectories, and the name of each file in the subdirectories. By this time, it should be fairly easy to see how we can use this information to inspect every file in every directory. \n",
    "\n",
    "Now, let's grab an email message. Messages in each folder just have numbers for names:\n",
    "\n",
    "<img align=\"center\" style=\"padding-right:10px;\" src=\"figures_wk4/allen_inbox.png\" width=600><br><br>\n",
    "\n",
    "So, let's get inbox message number 1:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "To:      k..allen@enron.com\n",
      "From:    heather.dunton@enron.com\n",
      "Cc:      None\n",
      "Date:    Fri, 7 Dec 2001 10:06:42 -0800 (PST)\n",
      "Subject: RE: West Position\n",
      "\n",
      "\n",
      "Body:  \n",
      "Please let me know if you still need Curve Shift.\n",
      "\n",
      "Thanks,\n",
      "Heather\n",
      " -----Original Message-----\n",
      "From: \tAllen, Phillip K.  \n",
      "Sent:\tFriday, December 07, 2001 5:14 AM\n",
      "To:\tDunton, Heather\n",
      "Subject:\tRE: West Position\n",
      "\n",
      "Heather,\n",
      "\n",
      "Did you attach the file to this email?\n",
      "\n",
      " -----Original Message-----\n",
      "From: \tDunton, Heather  \n",
      "Sent:\tWednesday, December 05, 2001 1:43 PM\n",
      "To:\tAllen, Phillip K.; Belden, Tim\n",
      "Subject:\tFW: West Position\n",
      "\n",
      "Attached is the Delta position for 1/16, 1/30, 6/19, 7/13, 9/21\n",
      "\n",
      "\n",
      " -----Original Message-----\n",
      "From: \tAllen, Phillip K.  \n",
      "Sent:\tWednesday, December 05, 2001 6:41 AM\n",
      "To:\tDunton, Heather\n",
      "Subject:\tRE: West Position\n",
      "\n",
      "Heather,\n",
      "\n",
      "This is exactly what we need.  Would it possible to add the prior day for each of the dates below to the pivot table.  In order to validate the curve shift on the dates below we also need the prior days ending positions.\n",
      "\n",
      "Thank you,\n",
      "\n",
      "Phillip Allen\n",
      "\n",
      " -----Original Message-----\n",
      "From: \tDunton, Heather  \n",
      "Sent:\tTuesday, December 04, 2001 3:12 PM\n",
      "To:\tBelden, Tim; Allen, Phillip K.\n",
      "Cc:\tDriscoll, Michael M.\n",
      "Subject:\tWest Position\n",
      "\n",
      "\n",
      "Attached is the Delta position for 1/18, 1/31, 6/20, 7/16, 9/24\n",
      "\n",
      "\n",
      "\n",
      " << File: west_delta_pos.xls >> \n",
      "\n",
      "Let me know if you have any questions.\n",
      "\n",
      "\n",
      "Heather\n"
     ]
    }
   ],
   "source": [
    "from email.parser import Parser\n",
    "\n",
    "file_to_read = allen + \"/inbox/1.\"\n",
    "\n",
    "# Open file and read in one big chunk\n",
    "with open(file_to_read, \"r\") as f:\n",
    "    data = f.read()\n",
    "\n",
    "# Use the email parser on the text chunk\n",
    "email = Parser().parsestr(data)\n",
    "\n",
    "# Print some of the email fields found by parser\n",
    "print(f\"To:      {email['to']}\")\n",
    "print(f\"From:    {email['from']}\")\n",
    "print(f\"Cc:      {email['cc']}\")\n",
    "print(f\"Date:    {email['date']}\")\n",
    "print(f\"Subject: {email['subject']}\")\n",
    "print(f\"\\n\\nBody: {email.get_payload()}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<hr>\n",
    "\n",
    "Hmmm. Interesting. This message had prior messages in the body text. If we *really* wanted to do this right, we would keep track of these conversations in some way so that they are searchable too. I think we'll leave that for another time. \n",
    "\n",
    "Now, let's look at creating our own custom email dataclass.\n",
    "\n",
    "<hr>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Aside: Python Dataclasses\n",
    "\n",
    "Python 3.7 introduced a great new language feature called **Dataclasses**.\n",
    "\n",
    "Classes, in general, can be described as containers for objects and the functions that modify the objects' attributes.  Dataclasses do the same thing with some shortcuts for those attributes.\n",
    "\n",
    "Several different ways to create data containers have been used, such as tuples or dictionaries, namedtuples, and a library called **attrs**, which was the inspiration for dataclasses. RealPython.com has a great dataclass tutorial that demonstrates all those methods and compares them to dataclasses, as well as showing more advanced usage of dataclasses than we will get into at https://realpython.com/python-data-classes/.\n",
    "\n",
    "After the typical `import` statement, we create a dataclass using a `@dataclass` **decorator**. Decorators are explained in more detail in MSDE 620, Week 5 and the tutorial at https://realpython.com/primer-on-python-decorators/. In brief, a decorator can be considered a \"wrapper\" around a function that modifies that function's behavior. \n",
    "\n",
    "In the the case of dataclasses, the decorator allows us to change the behavior of the `class` keyword\n",
    "\n",
    "Our class will be called `EmailMessage` and it will hold the attributes we printed from the test message: From, To, Cc, Date, Subject, Body.\n",
    "\n",
    "Let's see the definition."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "from dataclasses import dataclass\n",
    "from typing import List"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "@dataclass\n",
    "class MailMessage:\n",
    "    to_addr: List[str]\n",
    "    from_addr: str\n",
    "    cc: str\n",
    "    date: str\n",
    "    subject: str\n",
    "    body: str\n",
    "    \n",
    "    # Overriding the built-in string representation of MailMessage\n",
    "    # To make a message easier to read.\n",
    "    def __str__(self):\n",
    "        return f'TO: {self.to_addr}\\nFROM: {self.from_addr}\\nCC: {self.cc}\\nDATE: {self.date}\\nSUBJECT: {self.subject}\\n\\n{self.body}'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "That's all there is to it! Let's test it out by creating a fake email message."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TO: mickey@mouse.com\n",
      "FROM: daffy@duck.com\n",
      "CC: \n",
      "DATE: Tuesday, December 04, 2001 3:12 PM\n",
      "SUBJECT: Lunch tomorrow?\n",
      "\n",
      "Burgers at Five Guys around noon?\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'mickey@mouse.com'"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Single address\n",
    "myMsg = MailMessage('mickey@mouse.com', 'daffy@duck.com','','Tuesday, December 04, 2001 3:12 PM', 'Lunch tomorrow?', 'Burgers at Five Guys around noon?')\n",
    "print(myMsg)\n",
    "myMsg.to_addr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TO: ['mickey@mouse.com', 'minnie@mouse.com']\n",
      "FROM: daffy@duck.com\n",
      "CC: \n",
      "DATE: Tuesday, December 04, 2001 3:12 PM\n",
      "SUBJECT: Lunch tomorrow?\n",
      "\n",
      "Burgers at Five Guys around noon?\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['mickey@mouse.com', 'minnie@mouse.com']"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Multiple recipients\n",
    "myMsg = MailMessage(['mickey@mouse.com', 'minnie@mouse.com'], 'daffy@duck.com','','Tuesday, December 04, 2001 3:12 PM', 'Lunch tomorrow?', 'Burgers at Five Guys around noon?')\n",
    "print(myMsg)\n",
    "\n",
    "# This shows how to access an individual field. IMPORTANT LATER\n",
    "myMsg.to_addr"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I have one final concern. What does an email To: line look like with multiple recipients? Email 6 in the allen-p inbox has a bunch of recipients. Let's read it in and look at it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'tim.belden@enron.com, f..calger@enron.com, m..presto@enron.com, \\n\\tdavid.duran@enron.com, mitch.robinson@enron.com, \\n\\tdavid.forster@enron.com, mike.curry@enron.com, john.arnold@enron.com, \\n\\ts..shively@enron.com, rob.milnthorp@enron.com, \\n\\tjohn.zufferli@enron.com, laura.luce@enron.com, \\n\\tfrank.vickers@enron.com, scott.neal@enron.com, \\n\\tfred.lagrasta@enron.com, c..aucoin@enron.com, d..steffes@enron.com, \\n\\ta..roberts@enron.com, mike.grigsby@enron.com, \\n\\tbarry.tycholiz@enron.com, k..allen@enron.com, \\n\\tbrian.redmond@enron.com, a..martin@enron.com'"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "file_to_read = allen + \"/inbox/6.\"\n",
    "\n",
    "# Open file and read in one big chunk\n",
    "with open(file_to_read, \"r\") as f:\n",
    "    data = f.read()\n",
    "\n",
    "# Use the email parser on the text chunk\n",
    "email = Parser().parsestr(data)\n",
    "\n",
    "# Print email fields found by parser\n",
    "# print(f\"To:      {email['to']}\")\n",
    "# print(f\"From:    {email['from']}\")\n",
    "# print(f\"Cc:      {email['cc']}\")\n",
    "# print(f\"Date:    {email['date']}\")\n",
    "# print(f\"Subject: {email['subject']}\")\n",
    "# print(f\"\\n\\nBody: {email.get_payload()}\")\n",
    "email['to']\n",
    "# type(email['to'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Looks like a big, long string with some '\\n\\t' thrown in just to make our lives harder. Let's see if we can't turn that into a list."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'tim.belden@enron.com, f..calger@enron.com, m..presto@enron.com, david.duran@enron.com, mitch.robinson@enron.com, david.forster@enron.com, mike.curry@enron.com, john.arnold@enron.com, s..shively@enron.com, rob.milnthorp@enron.com, john.zufferli@enron.com, laura.luce@enron.com, frank.vickers@enron.com, scott.neal@enron.com, fred.lagrasta@enron.com, c..aucoin@enron.com, d..steffes@enron.com, a..roberts@enron.com, mike.grigsby@enron.com, barry.tycholiz@enron.com, k..allen@enron.com, brian.redmond@enron.com, a..martin@enron.com'"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "email_to = email['to']\n",
    "email_to = email_to.replace(\"\\n\\t\", \"\") # Replace with nothing, means delete them\n",
    "email_to"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'tim.belden@enron.com,f..calger@enron.com,m..presto@enron.com,david.duran@enron.com,mitch.robinson@enron.com,david.forster@enron.com,mike.curry@enron.com,john.arnold@enron.com,s..shively@enron.com,rob.milnthorp@enron.com,john.zufferli@enron.com,laura.luce@enron.com,frank.vickers@enron.com,scott.neal@enron.com,fred.lagrasta@enron.com,c..aucoin@enron.com,d..steffes@enron.com,a..roberts@enron.com,mike.grigsby@enron.com,barry.tycholiz@enron.com,k..allen@enron.com,brian.redmond@enron.com,a..martin@enron.com'"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Now let's get rid of the spaces\n",
    "# Saves having to use strip() later\n",
    "email_to = email_to.replace(\" \",\"\")\n",
    "email_to"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['tim.belden@enron.com',\n",
       " 'f..calger@enron.com',\n",
       " 'm..presto@enron.com',\n",
       " 'david.duran@enron.com',\n",
       " 'mitch.robinson@enron.com',\n",
       " 'david.forster@enron.com',\n",
       " 'mike.curry@enron.com',\n",
       " 'john.arnold@enron.com',\n",
       " 's..shively@enron.com',\n",
       " 'rob.milnthorp@enron.com',\n",
       " 'john.zufferli@enron.com',\n",
       " 'laura.luce@enron.com',\n",
       " 'frank.vickers@enron.com',\n",
       " 'scott.neal@enron.com',\n",
       " 'fred.lagrasta@enron.com',\n",
       " 'c..aucoin@enron.com',\n",
       " 'd..steffes@enron.com',\n",
       " 'a..roberts@enron.com',\n",
       " 'mike.grigsby@enron.com',\n",
       " 'barry.tycholiz@enron.com',\n",
       " 'k..allen@enron.com',\n",
       " 'brian.redmond@enron.com',\n",
       " 'a..martin@enron.com']"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Now the list\n",
    "email_to = email_to.split(',')\n",
    "email_to"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Looks like it works!\n",
    "\n",
    "Now, we could just write a loop to read in the emails, but I have plans for later. Let's make a function to help us."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def email_analyse(inputfile, mail_msg):\n",
    "    with open(inputfile, \"r\", encoding = \"ISO-8859-1\") as f:\n",
    "        data = f.read()\n",
    "\n",
    "    email = Parser().parsestr(data)\n",
    "    \n",
    "    if email['to']:\n",
    "        email_to = email['to']\n",
    "        email_to = email_to.replace(\"\\n\", \"\")\n",
    "        email_to = email_to.replace(\"\\t\", \"\")\n",
    "        email_to = email_to.replace(\" \", \"\")\n",
    "\n",
    "        email_to = email_to.split(\",\")\n",
    "    else:\n",
    "        email_to = []\n",
    "\n",
    "    from_email = email['from']\n",
    "\n",
    "    email_body = email.get_payload()\n",
    "    email_subject = email['subject']\n",
    "    email_cc = email['Cc']\n",
    "    email_date = email['date']\n",
    "    return mail_msg(email_to, from_email, email_cc, email_date, email_subject, email_body)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now let's test it on our two examples."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TO: ['k..allen@enron.com']\n",
      "FROM: heather.dunton@enron.com\n",
      "CC: None\n",
      "DATE: Fri, 7 Dec 2001 10:06:42 -0800 (PST)\n",
      "SUBJECT: RE: West Position\n",
      "\n",
      " \n",
      "Please let me know if you still need Curve Shift.\n",
      "\n",
      "Thanks,\n",
      "Heather\n",
      " -----Original Message-----\n",
      "From: \tAllen, Phillip K.  \n",
      "Sent:\tFriday, December 07, 2001 5:14 AM\n",
      "To:\tDunton, Heather\n",
      "Subject:\tRE: West Position\n",
      "\n",
      "Heather,\n",
      "\n",
      "Did you attach the file to this email?\n",
      "\n",
      " -----Original Message-----\n",
      "From: \tDunton, Heather  \n",
      "Sent:\tWednesday, December 05, 2001 1:43 PM\n",
      "To:\tAllen, Phillip K.; Belden, Tim\n",
      "Subject:\tFW: West Position\n",
      "\n",
      "Attached is the Delta position for 1/16, 1/30, 6/19, 7/13, 9/21\n",
      "\n",
      "\n",
      " -----Original Message-----\n",
      "From: \tAllen, Phillip K.  \n",
      "Sent:\tWednesday, December 05, 2001 6:41 AM\n",
      "To:\tDunton, Heather\n",
      "Subject:\tRE: West Position\n",
      "\n",
      "Heather,\n",
      "\n",
      "This is exactly what we need.  Would it possible to add the prior day for each of the dates below to the pivot table.  In order to validate the curve shift on the dates below we also need the prior days ending positions.\n",
      "\n",
      "Thank you,\n",
      "\n",
      "Phillip Allen\n",
      "\n",
      " -----Original Message-----\n",
      "From: \tDunton, Heather  \n",
      "Sent:\tTuesday, December 04, 2001 3:12 PM\n",
      "To:\tBelden, Tim; Allen, Phillip K.\n",
      "Cc:\tDriscoll, Michael M.\n",
      "Subject:\tWest Position\n",
      "\n",
      "\n",
      "Attached is the Delta position for 1/18, 1/31, 6/20, 7/16, 9/24\n",
      "\n",
      "\n",
      "\n",
      " << File: west_delta_pos.xls >> \n",
      "\n",
      "Let me know if you have any questions.\n",
      "\n",
      "\n",
      "Heather\n",
      "\n",
      "\n",
      "\n",
      "TO: ['tim.belden@enron.com', 'f..calger@enron.com', 'm..presto@enron.com', 'david.duran@enron.com', 'mitch.robinson@enron.com', 'david.forster@enron.com', 'mike.curry@enron.com', 'john.arnold@enron.com', 's..shively@enron.com', 'rob.milnthorp@enron.com', 'john.zufferli@enron.com', 'laura.luce@enron.com', 'frank.vickers@enron.com', 'scott.neal@enron.com', 'fred.lagrasta@enron.com', 'c..aucoin@enron.com', 'd..steffes@enron.com', 'a..roberts@enron.com', 'mike.grigsby@enron.com', 'barry.tycholiz@enron.com', 'k..allen@enron.com', 'brian.redmond@enron.com', 'a..martin@enron.com']\n",
      "FROM: louise.kitchen@enron.com\n",
      "CC: john.lavorato@enron.com\n",
      "DATE: Thu, 27 Dec 2001 14:58:02 -0800 (PST)\n",
      "SUBJECT: Re-start/Integration Planning\n",
      "\n",
      "We have for the last couple of weeks started to compile the Re-start/Integration Plans for Netco.  So far, we have primarily focussed on the mid/back plans where the technology requirements have been the driving factors.  Several plans are in the final stages of completion including:-\n",
      "\n",
      "+\tInfrastructure\t\tJenny Rub\n",
      "+\tDevelopment\t\tJay Webb\n",
      "+\tEnronOnline\t\tWebb / Forster\n",
      "+\tHR\t\t\tDavid Oxley\n",
      "+\tCash Management\tTom Myers\n",
      "+\tCredit\t\t\tDebbie Brackett\n",
      "\n",
      "The rest will be completed shortly.\n",
      "\n",
      "We now need to focus on the commercial plans which have a slightly different focus. John and I would like to receive the plans \"Re-start/Integration\"  plans by January 7th, 2002 in order to go through them individually with each of you or in groups.  The focus should be to ensure that we have as much of the business up and running in the shortest time possible.  I have a suggested outline which you do not have to use but I thought it might help.  Please decide within yourselves the areas you will cover together or individually.\n",
      "\n",
      "Customer Side\t\n",
      "+\tCustomers\t\tPhase  1 - First Week (eg top 10)\n",
      "\t\t\t\tPhase  2 - First Month (eg top 50)\n",
      "\t\t\t\tPhase  3 - First Quarter (eg top 100)\n",
      "+\tAction Plan\t\tPhase  1 Customers\n",
      "\t\t\t\tPhase  2 Customers\n",
      "\t\t\t\tPhase  3 Customers\n",
      "+\tContracts by customers (pre-prepared with credit terms etc)\n",
      "+\tCustomer visit schedule\n",
      "\n",
      "Product Side\n",
      "+\tList of Products\tPhase 1 - First Week\n",
      "\t\t\t\tPhase 2 - First Month\n",
      "\t\t\t\tPhase 3 - First Quarter\n",
      "\n",
      "Target Number of Transactions\n",
      "+\tPhase 1\n",
      "+\tPhase 2\n",
      "+\tPhase 3\n",
      "\n",
      "IT transfer \n",
      "\n",
      "Louise\n"
     ]
    }
   ],
   "source": [
    "msg1 = email_analyse(allen + '/inbox/1.', MailMessage)\n",
    "msg2 = email_analyse(allen + '/inbox/6.', MailMessage)\n",
    "\n",
    "print(msg1)\n",
    "print('\\n\\n')\n",
    "print(msg2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here's a function to return a list of files with full path."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "PurePosixPath('/Users/cpearson/Regis/Faculty/MSDE621/FTE_Content/Week4/maildir/allen-p/notes_inbox/36.')"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pathlib\n",
    "def pathlist(rootdir):\n",
    "    path_list = []\n",
    "    for directory, subdirectory, filenames in  os.walk(rootdir):\n",
    "        for name in filenames:\n",
    "            if name != '.DS_Store':\n",
    "                path_list.append(pathlib.PurePath(directory, name))\n",
    "    return path_list\n",
    "\n",
    "# A list of email files with full path in the allen-p directory\n",
    "path_list = pathlist(allen)\n",
    "path_list[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, we are going to use the %%time magic function to time how long it takes to read the emails."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Read 3034 mail messages.\n",
      "\n",
      "CPU times: user 515 ms, sys: 106 ms, total: 621 ms\n",
      "Wall time: 621 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "mail_list = []\n",
    "for fname in path_list:\n",
    "    msg = email_analyse(fname, MailMessage)\n",
    "    mail_list.append(msg)\n",
    "    \n",
    "print(f'Read {len(mail_list)} mail messages.\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "CPU time and Wall time are different because CPU time breaks code into \"user\" code and \"system\" code. Both together add up to the time you would get with a stopwatch. \n",
    "\n",
    "So it took between 1/2 and 2/3 of a second to do roughly 3000 emails. We may have a problem with 500,000. \n",
    "\n",
    "Enter, parallel processing...\n",
    "\n",
    "<hr>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img align=\"center\" style=\"padding-right:10px;\" src=\"figures_wk4/thistall.jpg\" width=400><br><br>\n",
    "-- Dave Baron, Mozilla developer\n",
    "\n",
    "## Background info - multithreading and multiprocessing\n",
    "\n",
    "**Definitions**\n",
    "\n",
    "* **Process**-- Generally, one program\n",
    "* **Thread**-- \"Lightweight\" process that shares memory with other threads\n",
    "* **Multiprocessing**-- One program with multiple parallel processes\n",
    "* **Multithreading**-- Multiple threads sharing memory for parallel processing\n",
    "\n",
    "Many times, when we have large, slow tasks, we break them up into smaller tasks and try to do more than one of them at once. Although there are other definitions and uses, this is called parallel processing. Unfortunately, Python was written before \"multi-core\" CPUs were even a concept. Due to this, a shortcut was taken to mitigate inherent problems with multi-threading: the Global Interpreter Lock (GIL). When one Python thread is running on the CPU, the GIL locks out all other Python threads. Also unfortunately, the GIL is such a fundamental part of the Python interpreter, it cannot really be removed to take advantage of modern CPUs.\n",
    "\n",
    "All hope is not lost, though. Python has no problem with multi-processing -- allowing one program to control multiple independent processes that do not share memory with each other.\n",
    "\n",
    "Also, the GIL only comes into play when a slow process is CPU-bound, like a difficult math problem. I/O (input/output)-bound programs do not have to deal with the GIL. Students are encouraged to do further investigation into multithreading and multiprocessing on their own.\n",
    "\n",
    "Since each email message resides on disk completely seperately from all other messages, there is nothing stopping us from reading several messages. Even though our mail parsing is I/O-bound, we will investigate multiprocessing to help speed up ingestion. **Note:** there are a few libraries and methods to help make multiprocessing easier but we will stay with the Python standard library tool, **concurrent futures.**\n",
    "\n",
    "As always, we start by importing the relevant libraries:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "import concurrent.futures\n",
    "from itertools import repeat"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We need the `repeat()` function from itertools to provide multiple MailMessage objects to the multiple processes we will create.\n",
    "\n",
    "The general workflow is that we will create a pool of processes and an executor object (all in one step) to give the processes work and collect the results. \n",
    "\n",
    "<img align=\"right\" style=\"padding-right:10px;\" src=\"figures_wk4/map.png\" width=200>\n",
    "\n",
    "The executor has a function called `map()` to do the dirty work. In general, `map()` functions exist to apply a transformation function to a collection of data. `map()` will take the `email_analyse()`, the `path_list` and the repeating `MailMessage` objects, and give us back an object containing all the messages. \n",
    "\n",
    "Let's see using the entire corpus:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "path_list = pathlist(rootdir)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-danger\">\n",
    "<b>Important::</b> Don't do this as a live demo. It takes several minutes!\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Read 520435 mail messages.\n",
      "\n",
      "CPU times: user 1min 57s, sys: 51.6 s, total: 2min 48s\n",
      "Wall time: 3min 53s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "for fname in path_list:\n",
    "    msg = email_analyse(fname, MailMessage)\n",
    "    mail_list.append(msg)\n",
    "    \n",
    "print(f'Read {len(mail_list)} mail messages.\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "That is processing time on my laptop.\n",
    "\n",
    "Now, let's try it in parallel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Read 517401 mail messages.\n",
      "\n",
      "CPU times: user 2min 53s, sys: 51 s, total: 3min 44s\n",
      "Wall time: 3min 56s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "with concurrent.futures.ProcessPoolExecutor() as executor:\n",
    "    results = list(executor.map(email_analyse, path_list, repeat(MailMessage)))\n",
    "    \n",
    "print(f'Read {len(results)} mail messages.\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Looks like roughly half the time. Not bad for only adding a couple of lines of code. \n",
    "\n",
    "Unfortunately, we can't use that same trick to load the database. Neither SQLite nor TinyDB are built for concurrent write operations. \n",
    "\n",
    "We will look at one possible way to store these emails in SQLite next.\n",
    "\n",
    "<hr>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Case 1 - Relational DB (SQLite3)\n",
    "\n",
    "OK, now that we have all the preliminary stuff out of the way, we can get down to the real business of storing the emails in a database and running queries against it. Consider the following message from the corpus:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TO: ['jarnold@enron.com']\n",
      "FROM: msagel@home.com\n",
      "CC: None\n",
      "DATE: Thu, 16 Nov 2000 09:30:00 -0800 (PST)\n",
      "SUBJECT: Status\n",
      "\n",
      "John:\n",
      "?\n",
      "I'm not really sure what happened between us.? I was  under the impression \n",
      "after my visit to Houston that we were about to enter into  a trial agreement \n",
      "for my advisory work.? Somehow,?this never  occurred.? Did I say or do \n",
      "something wrong to screw this  up???\n",
      "?\n",
      "I don't know if you've blown this whole thing off, but I still  hope you are \n",
      "interested in trying?to create an arrangement.? As a  courtesy, here is my \n",
      "report from this past weekend.? If you are no longer  interested in my work, \n",
      "please tell me so.??Best wishes,\n",
      "?\n",
      "Mark Sagel\n",
      "Psytech Analytics\n",
      "(410)308-0245? \n",
      " - energy2000-1112.doc\n"
     ]
    }
   ],
   "source": [
    "print(results[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<hr>\n",
    "\n",
    "Since this is *not* a software engineering course nor are we trying to build an email client, we will keep our database to one simple table with each column representing an attribute of the MailMessage class. \n",
    "\n",
    "| to_addr | from_addr | cc | date | subject | body |\n",
    "|---------|-----------|----|------|---------|------|\n",
    "| 'jarnold@enron.com' | 'msagel@home.com' | Null | 'Thu, 16 Nov 2000 09:30:00 -0800 (PST)' | 'Status' | \"John:\\n?\\nI'm not really sure what happened between us.? I was  under the impression \\nafter my visit to Houston that we were about to enter into  a trial agreement \\nfor my advisory work.? Somehow,?this never  occurred.? Did I say or do \\nsomething wrong to screw this  up???\\n?\\nI don't know if you've blown this whole thing off, but I still  hope you are \\ninterested in trying?to create an arrangement.? As a  courtesy, here is my \\nreport from this past weekend.? If you are no longer  interested in my work, \\nplease tell me so.??Best wishes,\\n?\\nMark Sagel\\nPsytech Analytics\\n(410)308-0245? \\n - energy2000-1112.doc\"|\n",
    "\n",
    "An argument could be made to also save the path of the message, but I don't feel like going back and adding it to the dataclass (wink).\n",
    "\n",
    "Two points also bear examination:\n",
    "\n",
    "Q: We have all the messages in memory right now, which is usually a first step to analysis. Why do we need a database?<br>\n",
    "A: First, because even though the dataclass help structure and organize the messages, it is still in a difficult form to search and filter, and second, *because this is a lesson on storing data in databases*.\n",
    "\n",
    "Q: Why didn't we just write the database insert step into the message parsing function?<br>\n",
    "A: That is certainly possible but in this exploratory format, we want to take small steps to build knowledge and confidence. Plus, software engineering best practices tell us that functions should only have one purpose.<br> **(OK, you got me, `email_analyse()` has two purposes -- (1)reading the message from disk into memory, and (2) parsing messages into the dataclass. I won't tell the software engineering nazis if you won't).**\n",
    "\n",
    "### Creating and inserting into a database with SQL\n",
    "\n",
    "Remember from Week 2 that DDL is the language that SQL uses to create tables. The raw DDL to create a table is \n",
    "\n",
    "```\n",
    "CREATE TABLE IF NOT EXISTS messages ();  # IF NOT EXISTS means only try to create if there isn't alreay one\n",
    "```\n",
    "\n",
    "We put the column names and types along with any constraints. To keep things simple, we will have a message_id field that is the integer Primary Key, everything else will be a string. The full statement looks like this:\n",
    "\n",
    "```\n",
    "CREATE TABLE IF NOT EXISTS messages (\n",
    "    message_id INTEGER PRIMARY KEY,      # notice commas between columns. \n",
    "    to_addr TEXT NOT NULL,               # We break it up to make it easy to read. \n",
    "    from_addr TEXT NOT NULL,             # This is actually one long line.\n",
    "    cc TEXT,                             # NOT NULL means we get an error if it is blank. \n",
    "    date TEXT NOT NULL,                  # cc can be blank but we want something in the other fields\n",
    "    subject TEXT,                        # emails can have blank subjects\n",
    "    body TEXT                            # no comma on the last one\n",
    ");\n",
    "```\n",
    "\n",
    "The `INSERT` statement will pair the columns with the dataclass's fields. Remember above where I showed how to access the `to_addr` and said it was important. Well, this is why. For a MailMessage object called myMsg, it would look like this:\n",
    "\n",
    "`INSERT INTO messages (to_addr, from_addr, cc, date, subject, body) VALUES (myMsg.to_addr, myMsg.from_addr, myMsg.cc, myMsg.date, myMsg.subject, myMsg.body);`\n",
    "\n",
    "That line of code should not come as a shock to anyone. We have seen all the pieces before, we are just scraping them all together here. \n",
    "\n",
    "Stick that `INSERT` line in a `for` loop and you are done!\n",
    "\n",
    "**Dataset** makes the process a bit easier. It automatically handles the create table and the if not exists. It will create the columns from the first insert statement.\n",
    "\n",
    "**BONUS** Dataclasses have an `asdict()` function that we can use in our insert!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'to_addr': ['jarnold@enron.com'],\n",
       " 'from_addr': 'msagel@home.com',\n",
       " 'cc': None,\n",
       " 'date': 'Thu, 16 Nov 2000 09:30:00 -0800 (PST)',\n",
       " 'subject': 'Status',\n",
       " 'body': \"John:\\n?\\nI'm not really sure what happened between us.? I was  under the impression \\nafter my visit to Houston that we were about to enter into  a trial agreement \\nfor my advisory work.? Somehow,?this never  occurred.? Did I say or do \\nsomething wrong to screw this  up???\\n?\\nI don't know if you've blown this whole thing off, but I still  hope you are \\ninterested in trying?to create an arrangement.? As a  courtesy, here is my \\nreport from this past weekend.? If you are no longer  interested in my work, \\nplease tell me so.??Best wishes,\\n?\\nMark Sagel\\nPsytech Analytics\\n(410)308-0245? \\n - energy2000-1112.doc\"}"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from dataclasses import asdict\n",
    "asdict(results[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-success\">\n",
    "<b>Installation - dataset::</b> You will need to install dataset before you can use it!\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: dataset in /opt/anaconda3/lib/python3.7/site-packages (1.1.2)\n",
      "Requirement already satisfied: six>=1.11.0 in /opt/anaconda3/lib/python3.7/site-packages (from dataset) (1.12.0)\n",
      "Requirement already satisfied: alembic>=0.6.2 in /opt/anaconda3/lib/python3.7/site-packages (from dataset) (1.3.1)\n",
      "Requirement already satisfied: sqlalchemy>=1.1.2 in /opt/anaconda3/lib/python3.7/site-packages (from dataset) (1.3.9)\n",
      "Requirement already satisfied: python-editor>=0.3 in /opt/anaconda3/lib/python3.7/site-packages (from alembic>=0.6.2->dataset) (1.0.4)\n",
      "Requirement already satisfied: Mako in /opt/anaconda3/lib/python3.7/site-packages (from alembic>=0.6.2->dataset) (1.1.0)\n",
      "Requirement already satisfied: python-dateutil in /opt/anaconda3/lib/python3.7/site-packages (from alembic>=0.6.2->dataset) (2.8.0)\n",
      "Requirement already satisfied: MarkupSafe>=0.9.2 in /opt/anaconda3/lib/python3.7/site-packages (from Mako->alembic>=0.6.2->dataset) (1.1.1)\n"
     ]
    }
   ],
   "source": [
    "!pip install dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "import dataset\n",
    "\n",
    "db = dataset.connect(\"sqlite:///data_wk4/mail_sql.db\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "msg_table = db.create_table('messages')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Only one last problem still stands in our way: We can't insert a list directly. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error: All manner of bad things would have happened.\n"
     ]
    }
   ],
   "source": [
    "row = asdict(results[0])\n",
    "\n",
    "try:\n",
    "    msg_table.insert(row)\n",
    "except:\n",
    "    print('Error: All manner of bad things would have happened.')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "But, if we convert that list to a long string, we are fine:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'to_addr': 'jarnold@enron.com',\n",
       " 'from_addr': 'msagel@home.com',\n",
       " 'cc': None,\n",
       " 'date': 'Thu, 16 Nov 2000 09:30:00 -0800 (PST)',\n",
       " 'subject': 'Status',\n",
       " 'body': \"John:\\n?\\nI'm not really sure what happened between us.? I was  under the impression \\nafter my visit to Houston that we were about to enter into  a trial agreement \\nfor my advisory work.? Somehow,?this never  occurred.? Did I say or do \\nsomething wrong to screw this  up???\\n?\\nI don't know if you've blown this whole thing off, but I still  hope you are \\ninterested in trying?to create an arrangement.? As a  courtesy, here is my \\nreport from this past weekend.? If you are no longer  interested in my work, \\nplease tell me so.??Best wishes,\\n?\\nMark Sagel\\nPsytech Analytics\\n(410)308-0245? \\n - energy2000-1112.doc\"}"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "row['to_addr'] = ','.join(row['to_addr'])\n",
    "row"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1040871"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "msg_table.insert(row)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finally, just to save our sanity, I'm going to use a little progress bar in my for loop."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|| 517400/517400 [09:19<00:00, 924.84it/s] \n"
     ]
    }
   ],
   "source": [
    "# Remember, we inserted row 0 above. Need it exclude it from this loop\n",
    "\n",
    "for msg in tqdm(results[1:]):\n",
    "    row = asdict(msg)\n",
    "    row['to_addr'] = ','.join(row['to_addr'])\n",
    "    msg_table.insert(row)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**WOW!** That took a bit of time to complete!\n",
    "\n",
    "<div class=\"alert alert-block alert-info\">\n",
    "<b>Helpful Hint::</b> ** ALWAYS ** check your work! Especially after such a lengthy data load. You really don't want to have to do that too many times!\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1558271"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(msg_table)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Everything with this database is goiong to seem slow **UNTIL** you put an `index` on a column. I'll leave it as bonus points to figure out how. It would be worth your time to look it up. We spent all this time building this database, so we are going use it a couple more times.\n",
    "\n",
    "Let's do a couple of queries."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cheating here. Using syntax from underlying SQLAlchemy library that Dataset is built on top of.\n",
    "# See https://dataset.readthedocs.io/en/latest/quickstart.html#running-custom-sql-queries\n",
    "table = db['messages'].table\n",
    "jarnold = table.select(table.c.to_addr.like('%john.arnold%')) \n",
    "result = db.query(jarnold)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "the_list = []\n",
    "for msg in result:\n",
    "    row = MailMessage(msg['to_addr'], msg['from_addr'], msg['cc'], msg['date'], msg['subject'], msg['body'])\n",
    "    the_list.append(row)\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10218 emails where john.arnold was recipient\n",
      "\n",
      "\n",
      "TO: alex.mcleish@enron.com,sarah.mulholland@enron.com,chris.mahoney@enron.com,david.botchlett@enron.com,john.arnold@enron.com,chris.gaskill@enron.com,julie.gomez@enron.com,elizabeth.shim@enron.com\n",
      "FROM: jennifer.fraser@enron.com\n",
      "CC: None\n",
      "DATE: Sun, 19 Nov 2000 09:34:00 -0800 (PST)\n",
      "SUBJECT: Fuel Switching\n",
      "\n",
      "The attached report contains an analysis of fuel switching capability. It \n",
      "also details one  of the current problems with EIA data. The EIA data  \n",
      "contains FERC form I data. Once generation is sold its fuel consumption is no \n",
      "longer reported to the DOE. Hence an analysis of the DOE cost  and quality of \n",
      "generation fuels is incomplete becasue of the lack of NUG data. WEFA gets \n",
      "around this by using 1998 FERC FORM I data. After 1998, there were \n",
      "significant sales of generation due to the ongoing legislation and \n",
      "deregulation at the state level.\n",
      "\n",
      "\n",
      " - NGM11_00.pdf\n"
     ]
    }
   ],
   "source": [
    "print(f'{len(the_list)} emails where john.arnold was recipient\\n\\n')\n",
    "print(the_list[3])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<hr>\n",
    "\n",
    "It may be just as easy to write raw SQL:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "like_result = db.query('select * from messages where to_addr like \"%john.arnold%\"')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_list = []\n",
    "for msg in like_result:\n",
    "    row = MailMessage(msg['to_addr'], msg['from_addr'], msg['cc'], msg['date'], msg['subject'], msg['body'])\n",
    "    new_list.append(row)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10218 emails where john.arnold was recipient\n",
      "\n",
      "\n",
      "TO: alex.mcleish@enron.com,sarah.mulholland@enron.com,chris.mahoney@enron.com,david.botchlett@enron.com,john.arnold@enron.com,chris.gaskill@enron.com,julie.gomez@enron.com,elizabeth.shim@enron.com\n",
      "FROM: jennifer.fraser@enron.com\n",
      "CC: None\n",
      "DATE: Sun, 19 Nov 2000 09:34:00 -0800 (PST)\n",
      "SUBJECT: Fuel Switching\n",
      "\n",
      "The attached report contains an analysis of fuel switching capability. It \n",
      "also details one  of the current problems with EIA data. The EIA data  \n",
      "contains FERC form I data. Once generation is sold its fuel consumption is no \n",
      "longer reported to the DOE. Hence an analysis of the DOE cost  and quality of \n",
      "generation fuels is incomplete becasue of the lack of NUG data. WEFA gets \n",
      "around this by using 1998 FERC FORM I data. After 1998, there were \n",
      "significant sales of generation due to the ongoing legislation and \n",
      "deregulation at the state level.\n",
      "\n",
      "\n",
      " - NGM11_00.pdf\n"
     ]
    }
   ],
   "source": [
    "# This should match what we got above\n",
    "print(f'{len(new_list)} emails where john.arnold was recipient\\n\\n')\n",
    "print(new_list[3])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<hr>\n",
    "\n",
    "This is just scratching the surface! For example, you can use the `between` operator to find messages sent in a timeframe."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "date_result = msg_table.find(date={'between':['Fri, 1 Dec 2000 00:00:00 -0800 (PST)','Fri, 1 Dec 2000 00:30:00 -0800 (PST)']})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "lst_date = list(date_result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "213"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(lst_date)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Future Steps\n",
    "\n",
    "As mentioned earilier, there are several improvements to the database design that could be made. For example,\n",
    "\n",
    "* The database could be normalized with a table of internal email addresses that link to the message table. In this case the From: field and potentially the To: field would be linked to the address table.\n",
    "* When the To: field has multiple recipients, the message could be duplicated for each recipient so that there is only ever one recipient on the To: line.\n",
    "* \"Threaded\" or long email chains could be separated from the current message and a table could be created to relate messages, replies, and addressing info.\n",
    "\n",
    "<hr>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Case 2 - NoSQL (TinyDB)\n",
    "\n",
    "TinyDB is a NoSQL document database that is implemented in 100% Python, meaning besides \"toy\" deployments like this, it is appropriate for places that don't allow for installing and building a C-based library such as mobile platforms or online interpreters. \n",
    "\n",
    "TinyDB stores documents formatted as dictionaries in a JSON file (unless this behavior is modified by plugins). This is great news for us because we already solved this problem above.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tinydb import TinyDB, Query\n",
    "db = TinyDB('data_wk4/enron_nosql.json')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The \"results\" variable holds the result of concurrently reading the emails from the data directory. Let's make sure how many items it has in it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "517401"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(results)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Since TinyDB uses a dictionary, the same as dataset, we can use the same code to construct the dictionary, with the caveat that JSON can handle the list in to_addr just fine."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-danger\">\n",
    "<b>Important::</b> Kill this off after a 1% completes\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  1%|          | 2912/517401 [02:48<15:16:14,  9.36it/s]"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-54-3b22516fa03d>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      2\u001b[0m     \u001b[0mrow\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0masdict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmsg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;31m#     row['to_addr'] = ','.join(row['to_addr'])\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m     \u001b[0mdb\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minsert\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrow\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/opt/anaconda3/lib/python3.7/site-packages/tinydb/database.py\u001b[0m in \u001b[0;36minsert\u001b[0;34m(self, document)\u001b[0m\n\u001b[1;32m    460\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    461\u001b[0m         \u001b[0mdoc_id\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_next_id\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 462\u001b[0;31m         \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_read\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    463\u001b[0m         \u001b[0mdata\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mdoc_id\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdocument\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    464\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_write\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda3/lib/python3.7/site-packages/tinydb/database.py\u001b[0m in \u001b[0;36m_read\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    409\u001b[0m         \"\"\"\n\u001b[1;32m    410\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 411\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_storage\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    412\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    413\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_write\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalues\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda3/lib/python3.7/site-packages/tinydb/database.py\u001b[0m in \u001b[0;36mread\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m     88\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     89\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 90\u001b[0;31m         \u001b[0mraw_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_storage\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     91\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     92\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda3/lib/python3.7/site-packages/tinydb/storages.py\u001b[0m in \u001b[0;36mread\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    114\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    115\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_handle\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mseek\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 116\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mjson\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_handle\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    117\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    118\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mwrite\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda3/lib/python3.7/json/__init__.py\u001b[0m in \u001b[0;36mload\u001b[0;34m(fp, cls, object_hook, parse_float, parse_int, parse_constant, object_pairs_hook, **kw)\u001b[0m\n\u001b[1;32m    294\u001b[0m         \u001b[0mcls\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcls\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mobject_hook\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mobject_hook\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    295\u001b[0m         \u001b[0mparse_float\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mparse_float\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mparse_int\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mparse_int\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 296\u001b[0;31m         parse_constant=parse_constant, object_pairs_hook=object_pairs_hook, **kw)\n\u001b[0m\u001b[1;32m    297\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    298\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda3/lib/python3.7/json/__init__.py\u001b[0m in \u001b[0;36mloads\u001b[0;34m(s, encoding, cls, object_hook, parse_float, parse_int, parse_constant, object_pairs_hook, **kw)\u001b[0m\n\u001b[1;32m    346\u001b[0m             \u001b[0mparse_int\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mparse_float\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32mand\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    347\u001b[0m             parse_constant is None and object_pairs_hook is None and not kw):\n\u001b[0;32m--> 348\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0m_default_decoder\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdecode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ms\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    349\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mcls\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    350\u001b[0m         \u001b[0mcls\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mJSONDecoder\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda3/lib/python3.7/json/decoder.py\u001b[0m in \u001b[0;36mdecode\u001b[0;34m(self, s, _w)\u001b[0m\n\u001b[1;32m    335\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    336\u001b[0m         \"\"\"\n\u001b[0;32m--> 337\u001b[0;31m         \u001b[0mobj\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mend\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mraw_decode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ms\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0midx\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0m_w\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ms\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    338\u001b[0m         \u001b[0mend\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_w\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ms\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mend\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    339\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mend\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ms\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda3/lib/python3.7/json/decoder.py\u001b[0m in \u001b[0;36mraw_decode\u001b[0;34m(self, s, idx)\u001b[0m\n\u001b[1;32m    351\u001b[0m         \"\"\"\n\u001b[1;32m    352\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 353\u001b[0;31m             \u001b[0mobj\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mend\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mscan_once\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ms\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0midx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    354\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mStopIteration\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0merr\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    355\u001b[0m             \u001b[0;32mraise\u001b[0m \u001b[0mJSONDecodeError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Expecting value\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0ms\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0merr\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalue\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "for msg in tqdm(results):\n",
    "    row = asdict(msg)\n",
    "#     row['to_addr'] = ','.join(row['to_addr'])\n",
    "    db.insert(row)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We are only 1% done.. Imagine how long it would take if we let is go to completion!!! Let's try the more advanced `insert_multiple()`. To do that, we'll need our dictionaries in a list. We can use a list comprehension for that."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "results_list = [asdict(msg) for msg in results]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Always check work..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "517401"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(results_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 9.96 s, sys: 3.19 s, total: 13.2 s\n",
      "Wall time: 14.5 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "id_list = db.insert_multiple(results_list)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "TinyDB's insert and `insert_multiple()` return the ID of the inserted record. Let's just make sure we have 517,402 of them."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "517401"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(id_list)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Hmmm... I wonder if SQLite has a bulk insert like that? Might be useful to find out...\n",
    "\n",
    "Let's do a couple of queries to match the SQLite ones we did above."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "query = Query()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "answer = db.search(query.to_addr.any('john.arnold@enron.com'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3927"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(answer)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Unfortunately, JSON doesn't handle datetime objects. There are a variety of ways to handle this in TinyDB including programmatically extending the serializer (code that writes records to disk). Perhaps the fastest and easiest method is to convert the timestamp to miliseconds and store that number to use in comparisons. Here is a simple little function to take that time string and output miliseconds as a floating point number. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "from dateutil.parser import parse\n",
    "from datetime import datetime\n",
    "\n",
    "def to_milis(timestring):\n",
    "    time = parse(timestring)\n",
    "    milis = datetime.timestamp(time)\n",
    "    return milis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "975657600.0"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "to_milis('Fri, 1 Dec 2000 00:00:00 -0800 (PST)')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "975659400.0"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "to_milis('Fri, 1 Dec 2000 00:30:00 -0800 (PST)')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "From here, we could either add this field to our dataclass or add the field to the dictionary before the data is stored, like this:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'to_addr': ['jarnold@enron.com'],\n",
       " 'from_addr': 'msagel@home.com',\n",
       " 'cc': None,\n",
       " 'date': 'Thu, 16 Nov 2000 09:30:00 -0800 (PST)',\n",
       " 'subject': 'Status',\n",
       " 'body': \"John:\\n?\\nI'm not really sure what happened between us.? I was  under the impression \\nafter my visit to Houston that we were about to enter into  a trial agreement \\nfor my advisory work.? Somehow,?this never  occurred.? Did I say or do \\nsomething wrong to screw this  up???\\n?\\nI don't know if you've blown this whole thing off, but I still  hope you are \\ninterested in trying?to create an arrangement.? As a  courtesy, here is my \\nreport from this past weekend.? If you are no longer  interested in my work, \\nplease tell me so.??Best wishes,\\n?\\nMark Sagel\\nPsytech Analytics\\n(410)308-0245? \\n - energy2000-1112.doc\"}"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test = results_list[0]\n",
    "test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "test['timestamp'] = to_milis(test['date'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'to_addr': ['jarnold@enron.com'],\n",
       " 'from_addr': 'msagel@home.com',\n",
       " 'cc': None,\n",
       " 'date': 'Thu, 16 Nov 2000 09:30:00 -0800 (PST)',\n",
       " 'subject': 'Status',\n",
       " 'body': \"John:\\n?\\nI'm not really sure what happened between us.? I was  under the impression \\nafter my visit to Houston that we were about to enter into  a trial agreement \\nfor my advisory work.? Somehow,?this never  occurred.? Did I say or do \\nsomething wrong to screw this  up???\\n?\\nI don't know if you've blown this whole thing off, but I still  hope you are \\ninterested in trying?to create an arrangement.? As a  courtesy, here is my \\nreport from this past weekend.? If you are no longer  interested in my work, \\nplease tell me so.??Best wishes,\\n?\\nMark Sagel\\nPsytech Analytics\\n(410)308-0245? \\n - energy2000-1112.doc\",\n",
       " 'timestamp': 974395800.0}"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this case, we'll use the `update()` method of dictionaries."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "for msg in results_list:\n",
    "    msg.update({'timestamp':to_milis(msg['date'])})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'to_addr': ['jarnold@enron.com'],\n",
       " 'from_addr': 'msagel@home.com',\n",
       " 'cc': None,\n",
       " 'date': 'Thu, 16 Nov 2000 09:30:00 -0800 (PST)',\n",
       " 'subject': 'Status',\n",
       " 'body': \"John:\\n?\\nI'm not really sure what happened between us.? I was  under the impression \\nafter my visit to Houston that we were about to enter into  a trial agreement \\nfor my advisory work.? Somehow,?this never  occurred.? Did I say or do \\nsomething wrong to screw this  up???\\n?\\nI don't know if you've blown this whole thing off, but I still  hope you are \\ninterested in trying?to create an arrangement.? As a  courtesy, here is my \\nreport from this past weekend.? If you are no longer  interested in my work, \\nplease tell me so.??Best wishes,\\n?\\nMark Sagel\\nPsytech Analytics\\n(410)308-0245? \\n - energy2000-1112.doc\",\n",
       " 'timestamp': 974395800.0}"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results_list[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, let's clear out the old data and insert the new. An empty db has a len() of 0."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "db.purge()\n",
    "len(db)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "id_list = db.insert_multiple(results_list)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finally, to do our between dates query:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "answer = db.search((query.timestamp >= to_milis('Fri, 1 Dec 2000 00:00:00 -0800 (PST)')) & (query.timestamp <= to_milis('Fri, 1 Dec 2000 00:30:00 -0800 (PST)')))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "71"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(answer)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<hr>\n",
    "\n",
    "## Future Steps\n",
    "\n",
    "As mentioned earilier, improvements could be made to the database design. For example,\n",
    "\n",
    "* Messages could have a \"Replies\" or \"RepliedTo\" field that contains a nested list of preceding messages. \n",
    "* Obviously, the timestamp could be handled better but if it was really important you may want to change databases"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
